{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee450c9d-c6c2-4d3b-8cc5-18fc9777f9d3",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-02T08:49:58.233262Z",
     "iopub.status.busy": "2024-07-02T08:49:58.232940Z",
     "iopub.status.idle": "2024-07-02T08:50:13.768628Z",
     "shell.execute_reply": "2024-07-02T08:50:13.768100Z",
     "shell.execute_reply.started": "2024-07-02T08:49:58.233241Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.schema import Document\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.6,\n",
    "    model=\"glm-4-0520\",\n",
    "    openai_api_key=\"661a7aa0aeb8ca129eb4647461123230.bl9w581QKpnMfBvs\",\n",
    "    openai_api_base=\"https://open.bigmodel.cn/api/paas/v4/\"\n",
    ")\n",
    "model_name = '/mnt/workspace/.cache/modelscope/hub/maple77/zpoint_large_embedding_zh'\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': True}\n",
    "hf = HuggingFaceBgeEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")\n",
    "langchain_llm = LangchainLLMWrapper(llm)\n",
    "langchain_embeddings = LangchainEmbeddingsWrapper(hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2ca600f0-7afe-497d-80e4-e1d9ffa5565b",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-02T12:14:03.570562Z",
     "iopub.status.busy": "2024-07-02T12:14:03.570231Z",
     "iopub.status.idle": "2024-07-02T12:14:03.573660Z",
     "shell.execute_reply": "2024-07-02T12:14:03.572854Z",
     "shell.execute_reply.started": "2024-07-02T12:14:03.570538Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_relevancy,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    ")\n",
    "\n",
    "# results = evaluate(metrics=[faithfulness], llm=langchain_llm, embeddings=langchain_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9924a9cb-11a4-4469-b636-32caf24d9fef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T08:52:54.808199Z",
     "iopub.status.busy": "2024-07-02T08:52:54.807854Z",
     "iopub.status.idle": "2024-07-02T08:53:20.769554Z",
     "shell.execute_reply": "2024-07-02T08:53:20.769095Z",
     "shell.execute_reply.started": "2024-07-02T08:52:54.808178Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import ArxivLoader\n",
    "\n",
    "paper_docs = ArxivLoader(query=\"2309.15217\", load_max_docs=1).load()\n",
    "len(paper_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70354e6a-f620-411a-9b99-38729caf6e34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for doc in paper_docs:\n",
    "    print(doc.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d1774d9-545c-4f6b-ba6b-e89ec16d8bec",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-02T08:53:36.115502Z",
     "iopub.status.busy": "2024-07-02T08:53:36.115178Z",
     "iopub.status.idle": "2024-07-02T08:57:39.032444Z",
     "shell.execute_reply": "2024-07-02T08:57:39.031858Z",
     "shell.execute_reply.started": "2024-07-02T08:53:36.115482Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500)\n",
    "\n",
    "docs = text_splitter.split_documents(paper_docs)\n",
    "\n",
    "vectorstore = Chroma.from_documents(docs, hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2332678d-90c2-4914-bbe0-d312d36eb277",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T08:58:31.382411Z",
     "iopub.status.busy": "2024-07-02T08:58:31.382034Z",
     "iopub.status.idle": "2024-07-02T08:58:31.386862Z",
     "shell.execute_reply": "2024-07-02T08:58:31.386174Z",
     "shell.execute_reply.started": "2024-07-02T08:58:31.382386Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['context', 'question'] template=\"You are an assistant for question-answering tasks. \\nUse the following pieces of retrieved context to answer the question. \\nIf you don't know the answer, just say that you don't know. \\n\\nQuestion: {question} \\n\\nContext: {context} \\n\\nAnswer:\\n\"\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "template = \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "\n",
    "Question: {question} \n",
    "\n",
    "Context: {context} \n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template, \n",
    "    input_variables=[\"context\",\"question\"]\n",
    "  )\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e89370c4-1fd0-4a14-8d27-ad5f231b4e61",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-02T08:59:13.909011Z",
     "iopub.status.busy": "2024-07-02T08:59:13.908669Z",
     "iopub.status.idle": "2024-07-02T08:59:13.912936Z",
     "shell.execute_reply": "2024-07-02T08:59:13.912470Z",
     "shell.execute_reply.started": "2024-07-02T08:59:13.908991Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "base_retriever = vectorstore.as_retriever(search_kwargs={\"k\" : 3})\n",
    "rag_chain = (\n",
    "    {\"context\": base_retriever,  \"question\": RunnablePassthrough()} \n",
    "    | prompt \n",
    "    | llm\n",
    "    | StrOutputParser() \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4244e278-0b80-4caa-a74c-d13e3cbe483b",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2024-07-02T11:01:19.064036Z",
     "iopub.status.busy": "2024-07-02T11:01:19.063708Z",
     "iopub.status.idle": "2024-07-02T11:03:01.396796Z",
     "shell.execute_reply": "2024-07-02T11:03:01.394453Z",
     "shell.execute_reply.started": "2024-07-02T11:01:19.064015Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from langchain_community.chat_models import ChatZhipuAI\n",
    "from langchain_community.chat_models import ChatZhipuAI\n",
    "import os\n",
    "\n",
    "os.environ[\"ZHIPUAI_API_KEY\"] = \"661a7aa0aeb8ca129eb4647461123230.bl9w581QKpnMfBvs\"\n",
    "questions = [\"What is faithfulness ?\", \n",
    "             \"How many pages are included in the WikiEval dataset, and which years do they cover information from?\",\n",
    "             \"Why is evaluating Retrieval Augmented Generation (RAG) systems challenging?\",\n",
    "            ]\n",
    "ground_truths = [\"Faithfulness refers to the idea that the answer should be grounded in the given context.\",\n",
    "                 \" To construct the dataset, we first selected 50 Wikipedia pages covering events that have happened since the start of 2022.\",\n",
    "                \"Evaluating RAG architectures is, however, challenging because there are several dimensions to consider: the ability of the retrieval system to identify relevant and focused context passages, the ability of the LLM to exploit such passages in a faithful way, or the quality of the generation itself.\"]\n",
    "answers = []\n",
    "contexts = []\n",
    "\n",
    "# 生成答案\n",
    "for query in questions:\n",
    "    answers.append(rag_chain.invoke(query))\n",
    "    contexts.append([docs.page_content for docs in base_retriever.get_relevant_documents(query)])\n",
    "\n",
    "# 构建数据\n",
    "data = {\n",
    "    \"question\": questions,\n",
    "    \"answer\": answers,\n",
    "    \"contexts\": contexts,\n",
    "    \"ground_truth\": ground_truths\n",
    "}\n",
    "dataset = Dataset.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bcbe4779-a734-4b3b-9d7e-c0b612375cbe",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-02T11:03:01.397996Z",
     "iopub.status.busy": "2024-07-02T11:03:01.397777Z",
     "iopub.status.idle": "2024-07-02T11:03:01.403512Z",
     "shell.execute_reply": "2024-07-02T11:03:01.403066Z",
     "shell.execute_reply.started": "2024-07-02T11:03:01.397974Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer', 'contexts', 'ground_truth'],\n",
       "    num_rows: 3\n",
       "})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d9bb16b7-6694-4fc0-878d-623f5f8526d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T11:03:29.631552Z",
     "iopub.status.busy": "2024-07-02T11:03:29.631219Z",
     "iopub.status.idle": "2024-07-02T11:03:56.178679Z",
     "shell.execute_reply": "2024-07-02T11:03:56.178157Z",
     "shell.execute_reply.started": "2024-07-02T11:03:29.631531Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bd6d440be2e43ca83023f0ba7312cf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'faithfulness': 1.0000, 'answer_relevancy': 0.9262, 'context_recall': 0.7500, 'context_precision': 0.9444}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat = ChatZhipuAI(\n",
    "    model=\"glm-4-0520\",\n",
    "    temperature=0.5,\n",
    ")\n",
    "metrics = [\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_recall,\n",
    "    context_precision\n",
    "]\n",
    "results = evaluate(dataset = dataset, metrics=metrics, llm=chat, embeddings=langchain_embeddings)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b1f5a2-5c44-4359-b38e-58a9dab27eb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fcf29d-f1e4-46cf-9e91-114fb509fc7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade httpx httpx-sse PyJWT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6fbd3345-130f-494a-a708-bc1dfa46a732",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-02T12:16:48.782244Z",
     "iopub.status.busy": "2024-07-02T12:16:48.781851Z",
     "iopub.status.idle": "2024-07-02T12:16:48.785525Z",
     "shell.execute_reply": "2024-07-02T12:16:48.784946Z",
     "shell.execute_reply.started": "2024-07-02T12:16:48.782220Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "chat2 = ChatZhipuAI(\n",
    "    model=\"embedding-2\",\n",
    "    temperature=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88348368-8fa2-43d1-9a32-ada6f81658cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
