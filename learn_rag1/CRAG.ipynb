{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05507dd7-bd38-47d8-9c63-b91dd103d00a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T06:36:21.064381Z",
     "iopub.status.busy": "2024-07-09T06:36:21.063982Z",
     "iopub.status.idle": "2024-07-09T06:36:35.372954Z",
     "shell.execute_reply": "2024-07-09T06:36:35.372453Z",
     "shell.execute_reply.started": "2024-07-09T06:36:21.064351Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "documents = []\n",
    "dc_name = [\"soybean_konw.pdf\", \"soybean2.pdf\"]\n",
    "for tmp_name in dc_name:\n",
    "    # print(len(PyPDFLoader(tmp_name).load()))\n",
    "    documents += PyPDFLoader(tmp_name).load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=200)\n",
    "texts = text_splitter.split_documents(documents[:])\n",
    "for idx, text in enumerate(texts):\n",
    "    text.metadata[\"id\"] = idx\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.schema import Document\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n",
    "top_k = 3\n",
    "\n",
    "model_name = '/mnt/workspace/.cache/modelscope/hub/maple77/zpoint_large_embedding_zh'\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': True}\n",
    "hf = HuggingFaceBgeEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")\n",
    "vectorstore = Chroma(persist_directory=\"soybean_db2\", embedding_function=hf)\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": top_k}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a467a593-ba3f-4bab-9fe9-e9ddb94f0e9f",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-09T07:21:52.195548Z",
     "iopub.status.busy": "2024-07-09T07:21:52.195204Z",
     "iopub.status.idle": "2024-07-09T07:21:52.284550Z",
     "shell.execute_reply": "2024-07-09T07:21:52.284064Z",
     "shell.execute_reply.started": "2024-07-09T07:21:52.195528Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing import List\n",
    "from typing import Literal, Optional, Tuple\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "# Data model\n",
    "class GradeDocuments(BaseModel):\n",
    "    \"\"\"Binary score for relevance check on retrieved documents.\"\"\"\n",
    "\n",
    "    binary_score: Literal[\"yes\", \"no\"] = Field(\n",
    "        ...,\n",
    "        description=\"Documents are relevant to the question, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "# LLM with function call\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.6,\n",
    "    model=\"glm-4-0520\",\n",
    "    openai_api_key=\"661a7aa0aeb8ca129eb4647461123230.bl9w581QKpnMfBvs\",\n",
    "    openai_api_base=\"https://open.bigmodel.cn/api/paas/v4/\"\n",
    ")\n",
    "# structured_llm_grader = llm.with_structured_output(GradeDocuments)\n",
    "# Set up a parser\n",
    "parser = PydanticOutputParser(pydantic_object=GradeDocuments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4420b96b-0e36-4748-8c06-ec553e4d20d0",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-09T07:25:34.034897Z",
     "iopub.status.busy": "2024-07-09T07:25:34.034549Z",
     "iopub.status.idle": "2024-07-09T07:25:38.170347Z",
     "shell.execute_reply": "2024-07-09T07:25:38.169828Z",
     "shell.execute_reply.started": "2024-07-09T07:25:34.034877Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_score='no'\n"
     ]
    }
   ],
   "source": [
    "# Prompt\n",
    "system = \"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n \n",
    "    If the document contains keyword(s) or semantic meaning related to the question, grade it as relevant. \\n\n",
    "    Answer the user query. Wrap the output in `json` tags\\n{format_instructions}\"\"\"\n",
    "grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Retrieved document: \\n\\n {document} \\n\\n User question: {question}\"),\n",
    "    ]\n",
    ").partial(format_instructions=parser.get_format_instructions())\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.6,\n",
    "    model=\"glm-4-0520\",\n",
    "    openai_api_key=\"661a7aa0aeb8ca129eb4647461123230.bl9w581QKpnMfBvs\",\n",
    "    openai_api_base=\"https://open.bigmodel.cn/api/paas/v4/\"\n",
    ")\n",
    "\n",
    "retrieval_grader = grade_prompt | llm | parser\n",
    "question = \"agent memory\"\n",
    "docs = retriever.get_relevant_documents(question)\n",
    "doc_txt = texts[3].page_content\n",
    "print(retrieval_grader.invoke({\"question\": question, \"document\": doc_txt}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69a4074e-c097-4e84-bbd4-b5ca460486b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T06:37:45.956466Z",
     "iopub.status.busy": "2024-07-09T06:37:45.956118Z",
     "iopub.status.idle": "2024-07-09T06:37:48.923769Z",
     "shell.execute_reply": "2024-07-09T06:37:48.923133Z",
     "shell.execute_reply.started": "2024-07-09T06:37:45.956445Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know.\n"
     ]
    }
   ],
   "source": [
    "### Generate\n",
    "\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Prompt\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "# LLM\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.6,\n",
    "    model=\"glm-4-0520\",\n",
    "    openai_api_key=\"661a7aa0aeb8ca129eb4647461123230.bl9w581QKpnMfBvs\",\n",
    "    openai_api_base=\"https://open.bigmodel.cn/api/paas/v4/\"\n",
    ")\n",
    "\n",
    "\n",
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Chain\n",
    "rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# Run\n",
    "generation = rag_chain.invoke({\"context\": docs, \"question\": question})\n",
    "print(generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4389fa9d-c605-48b0-af99-a61a6232e3cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T06:38:11.250407Z",
     "iopub.status.busy": "2024-07-09T06:38:11.250047Z",
     "iopub.status.idle": "2024-07-09T06:38:14.596950Z",
     "shell.execute_reply": "2024-07-09T06:38:14.596494Z",
     "shell.execute_reply.started": "2024-07-09T06:38:11.250386Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To enhance the searchability of the query \"agent memory,\" it would be beneficial to specify what kind of agent is being referred to and what aspect of memory is of interest. Here\\'s a revised question that provides more context:\\n\\n\"What are the types and capacities of memory in AI agents or software agents, and how are they utilized?\"\\n\\nThis question is more specific and should yield results related to the memory capabilities of artificial or software agents, including how they process and retain information.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Question Re-writer\n",
    "\n",
    "# LLM\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.6,\n",
    "    model=\"glm-4-0520\",\n",
    "    openai_api_key=\"661a7aa0aeb8ca129eb4647461123230.bl9w581QKpnMfBvs\",\n",
    "    openai_api_base=\"https://open.bigmodel.cn/api/paas/v4/\"\n",
    ")\n",
    "\n",
    "# Prompt\n",
    "system = \"\"\"You a question re-writer that converts an input question to a better version that is optimized \\n \n",
    "     for web search. Look at the input and try to reason about the underlying semantic intent / meaning.\"\"\"\n",
    "re_write_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Here is the initial question: \\n\\n {question} \\n Formulate an improved question.\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_rewriter = re_write_prompt | llm | StrOutputParser()\n",
    "question_rewriter.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0d793a2-b5e9-4fcf-8f58-df29667d2aa2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T06:47:18.803321Z",
     "iopub.status.busy": "2024-07-09T06:47:18.802882Z",
     "iopub.status.idle": "2024-07-09T06:47:28.896676Z",
     "shell.execute_reply": "2024-07-09T06:47:28.895991Z",
     "shell.execute_reply.started": "2024-07-09T06:47:18.803259Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "TimeoutException",
     "evalue": "https://duckduckgo.com Exception: Error in request: error sending request for url (https://duckduckgo.com/): operation timed out",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/duckduckgo_search/duckduckgo_search.py:104\u001b[0m, in \u001b[0;36mDDGS._get_url\u001b[0;34m(self, method, url, params, content, data)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 104\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
      "\u001b[0;31mException\u001b[0m: Error in request: error sending request for url (https://duckduckgo.com/): operation timed out",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTimeoutException\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# web_search_tool = TavilySearchResults(k=3)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m web_search_tool \u001b[38;5;241m=\u001b[39m DuckDuckGoSearchResults(k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mweb_search_tool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mObama\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/langchain_core/tools.py:452\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, **kwargs)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mException\u001b[39;00m, \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    451\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_tool_error(e)\n\u001b[0;32m--> 452\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    454\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_tool_end(observation, color\u001b[38;5;241m=\u001b[39mcolor, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/langchain_core/tools.py:409\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, **kwargs)\u001b[0m\n\u001b[1;32m    406\u001b[0m     parsed_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_input(tool_input)\n\u001b[1;32m    407\u001b[0m     tool_args, tool_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_to_args_and_kwargs(parsed_input)\n\u001b[1;32m    408\u001b[0m     observation \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 409\u001b[0m         \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtool_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtool_kwargs\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    412\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    413\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m context\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run, \u001b[38;5;241m*\u001b[39mtool_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtool_kwargs)\n\u001b[1;32m    414\u001b[0m     )\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ValidationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    416\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_validation_error:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/langchain_community/tools/ddg_search/tool.py:65\u001b[0m, in \u001b[0;36mDuckDuckGoSearchResults._run\u001b[0;34m(self, query, run_manager)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run\u001b[39m(\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     61\u001b[0m     query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m     62\u001b[0m     run_manager: Optional[CallbackManagerForToolRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     63\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m     64\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Use the tool.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_wrapper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresults\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_results\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m     res_strs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m d\u001b[38;5;241m.\u001b[39mitems()]) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m res]\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m rs \u001b[38;5;129;01min\u001b[39;00m res_strs])\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/langchain_community/utilities/duckduckgo_search.py:126\u001b[0m, in \u001b[0;36mDuckDuckGoSearchAPIWrapper.results\u001b[0;34m(self, query, max_results, source)\u001b[0m\n\u001b[1;32m    122\u001b[0m source \u001b[38;5;241m=\u001b[39m source \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m source \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    124\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    125\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msnippet\u001b[39m\u001b[38;5;124m\"\u001b[39m: r[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m: r[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlink\u001b[39m\u001b[38;5;124m\"\u001b[39m: r[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhref\u001b[39m\u001b[38;5;124m\"\u001b[39m]}\n\u001b[0;32m--> 126\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ddgs_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_results\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m     ]\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m source \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnews\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    129\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    130\u001b[0m         {\n\u001b[1;32m    131\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msnippet\u001b[39m\u001b[38;5;124m\"\u001b[39m: r[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ddgs_news(query, max_results\u001b[38;5;241m=\u001b[39mmax_results)\n\u001b[1;32m    138\u001b[0m     ]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/langchain_community/utilities/duckduckgo_search.py:63\u001b[0m, in \u001b[0;36mDuckDuckGoSearchAPIWrapper._ddgs_text\u001b[0;34m(self, query, max_results)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mduckduckgo_search\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DDGS\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m DDGS() \u001b[38;5;28;01mas\u001b[39;00m ddgs:\n\u001b[0;32m---> 63\u001b[0m     ddgs_gen \u001b[38;5;241m=\u001b[39m \u001b[43mddgs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m        \u001b[49m\u001b[43mregion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m        \u001b[49m\u001b[43msafesearch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msafesearch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimelimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_results\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ddgs_gen:\n\u001b[1;32m     72\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [r \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m ddgs_gen]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/duckduckgo_search/duckduckgo_search.py:200\u001b[0m, in \u001b[0;36mDDGS.text\u001b[0;34m(self, keywords, region, safesearch, timelimit, backend, max_results)\u001b[0m\n\u001b[1;32m    197\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlxml is not installed. Using backend=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapi\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapi\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 200\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_text_api\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeywords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafesearch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimelimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_results\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m backend \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhtml\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    202\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_text_html(keywords, region, timelimit, max_results)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/duckduckgo_search/duckduckgo_search.py:234\u001b[0m, in \u001b[0;36mDDGS._text_api\u001b[0;34m(self, keywords, region, safesearch, timelimit, max_results)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"DuckDuckGo text search. Query params: https://duckduckgo.com/params.\u001b[39;00m\n\u001b[1;32m    216\u001b[0m \n\u001b[1;32m    217\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;124;03m    TimeoutException: Inherits from DuckDuckGoSearchException, raised for API request timeouts.\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m keywords, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeywords is mandatory\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 234\u001b[0m vqd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_vqd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeywords\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m payload \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m\"\u001b[39m: keywords,\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkl\u001b[39m\u001b[38;5;124m\"\u001b[39m: region,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mex\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    246\u001b[0m }\n\u001b[1;32m    247\u001b[0m safesearch \u001b[38;5;241m=\u001b[39m safesearch\u001b[38;5;241m.\u001b[39mlower()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/duckduckgo_search/duckduckgo_search.py:120\u001b[0m, in \u001b[0;36mDDGS._get_vqd\u001b[0;34m(self, keywords)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_vqd\u001b[39m(\u001b[38;5;28mself\u001b[39m, keywords: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    119\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get vqd value for a search query.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m     resp_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_url\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttps://duckduckgo.com\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mq\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeywords\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _extract_vqd(resp_content, keywords)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/duckduckgo_search/duckduckgo_search.py:108\u001b[0m, in \u001b[0;36mDDGS._get_url\u001b[0;34m(self, method, url, params, content, data)\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception_event\u001b[38;5;241m.\u001b[39mset()\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(ex)\u001b[38;5;241m.\u001b[39mlower():\n\u001b[0;32m--> 108\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m TimeoutException(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(ex)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mex\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mex\u001b[39;00m\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DuckDuckGoSearchException(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(ex)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mex\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mex\u001b[39;00m\n\u001b[1;32m    110\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_get_url() \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresp\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresp\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(resp\u001b[38;5;241m.\u001b[39mcontent)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTimeoutException\u001b[0m: https://duckduckgo.com Exception: Error in request: error sending request for url (https://duckduckgo.com/): operation timed out"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_community.tools import DuckDuckGoSearchResults\n",
    "# web_search_tool = TavilySearchResults(k=3)\n",
    "web_search_tool = DuckDuckGoSearchResults(k=3)\n",
    "web_search_tool.run(\"Obama\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0656ca6a-5505-4cf7-8b7e-83c604988ff6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T07:22:09.920803Z",
     "iopub.status.busy": "2024-07-09T07:22:09.920483Z",
     "iopub.status.idle": "2024-07-09T07:22:09.924141Z",
     "shell.execute_reply": "2024-07-09T07:22:09.923544Z",
     "shell.execute_reply.started": "2024-07-09T07:22:09.920784Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        question: question\n",
    "        generation: LLM generation\n",
    "        web_search: whether to add search\n",
    "        documents: list of documents\n",
    "    \"\"\"\n",
    "\n",
    "    question: str\n",
    "    generation: str\n",
    "    web_search: str\n",
    "    documents: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "09bdf65f-85b2-4f0e-9b2e-59e0314f865a",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-09T07:26:41.026547Z",
     "iopub.status.busy": "2024-07-09T07:26:41.026183Z",
     "iopub.status.idle": "2024-07-09T07:26:41.029794Z",
     "shell.execute_reply": "2024-07-09T07:26:41.029358Z",
     "shell.execute_reply.started": "2024-07-09T07:26:41.026527Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "\n",
    "def retrieve(state):\n",
    "    \"\"\"\n",
    "    Retrieve documents\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, documents, that contains retrieved documents\n",
    "    \"\"\"\n",
    "    print(\"---RETRIEVE---\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # Retrieval\n",
    "    documents = retriever.invoke(question)\n",
    "    return {\"documents\": documents, \"question\": question}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "11ad59ca-520c-4f64-a582-3ebbc48a54c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T07:22:13.166648Z",
     "iopub.status.busy": "2024-07-09T07:22:13.166314Z",
     "iopub.status.idle": "2024-07-09T07:22:13.169879Z",
     "shell.execute_reply": "2024-07-09T07:22:13.169456Z",
     "shell.execute_reply.started": "2024-07-09T07:22:13.166628Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate(state):\n",
    "    \"\"\"\n",
    "    Generate answer\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation, that contains LLM generation\n",
    "    \"\"\"\n",
    "    print(\"---GENERATE---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # RAG generation\n",
    "    generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
    "    return {\"documents\": documents, \"question\": question, \"generation\": generation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0cac5c1c-1989-4f4a-9336-3627f98322a4",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-09T07:23:00.940969Z",
     "iopub.status.busy": "2024-07-09T07:23:00.940638Z",
     "iopub.status.idle": "2024-07-09T07:23:00.945167Z",
     "shell.execute_reply": "2024-07-09T07:23:00.944703Z",
     "shell.execute_reply.started": "2024-07-09T07:23:00.940950Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def grade_documents(state):\n",
    "    \"\"\"\n",
    "    Determines whether the retrieved documents are relevant to the question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Updates documents key with only filtered relevant documents\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECK DOCUMENT RELEVANCE TO QUESTION---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # Score each doc\n",
    "    filtered_docs = []\n",
    "    web_search = \"No\"\n",
    "    # print(documents)\n",
    "    for d in documents:\n",
    "        # print(d.page_content)\n",
    "        score = retrieval_grader.invoke(\n",
    "            {\"question\": question, \"document\": d.page_content}\n",
    "        )\n",
    "        print(score)\n",
    "        grade = score.binary_score\n",
    "        if grade == \"yes\":\n",
    "            print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
    "            filtered_docs.append(d)\n",
    "        else:\n",
    "            print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n",
    "            web_search = \"Yes\"\n",
    "            continue\n",
    "    return {\"documents\": filtered_docs, \"question\": question, \"web_search\": web_search}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0f394e70-1b43-4d83-86ea-0936455bfdb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T07:22:31.076730Z",
     "iopub.status.busy": "2024-07-09T07:22:31.076261Z",
     "iopub.status.idle": "2024-07-09T07:22:31.080845Z",
     "shell.execute_reply": "2024-07-09T07:22:31.080312Z",
     "shell.execute_reply.started": "2024-07-09T07:22:31.076700Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def transform_query(state):\n",
    "    \"\"\"\n",
    "    Transform the query to produce a better question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Updates question key with a re-phrased question\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---TRANSFORM QUERY---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # Re-write question\n",
    "    better_question = question_rewriter.invoke({\"question\": question})\n",
    "    return {\"documents\": documents, \"question\": better_question}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "33a17693-382e-48bf-a986-cd2dc4ce0da8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T07:22:34.845633Z",
     "iopub.status.busy": "2024-07-09T07:22:34.845304Z",
     "iopub.status.idle": "2024-07-09T07:22:34.848955Z",
     "shell.execute_reply": "2024-07-09T07:22:34.848500Z",
     "shell.execute_reply.started": "2024-07-09T07:22:34.845615Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def web_search(state):\n",
    "    \"\"\"\n",
    "    Web search based on the re-phrased question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Updates documents key with appended web results\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---WEB SEARCH---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # Web search\n",
    "    # docs = web_search_tool.invoke({\"query\": question})\n",
    "    # web_results = \"\\n\".join([d[\"content\"] for d in docs])\n",
    "    web_results = Document(page_content='web search result')\n",
    "    documents.append(web_results)\n",
    "\n",
    "    return {\"documents\": documents, \"question\": question}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fefaf85f-ad8c-468e-a2d3-0f6e26bb1d85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T07:22:36.970024Z",
     "iopub.status.busy": "2024-07-09T07:22:36.969704Z",
     "iopub.status.idle": "2024-07-09T07:22:36.973578Z",
     "shell.execute_reply": "2024-07-09T07:22:36.973024Z",
     "shell.execute_reply.started": "2024-07-09T07:22:36.970005Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def decide_to_generate(state):\n",
    "    \"\"\"\n",
    "    Determines whether to generate an answer, or re-generate a question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Binary decision for next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---ASSESS GRADED DOCUMENTS---\")\n",
    "    state[\"question\"]\n",
    "    web_search = state[\"web_search\"]\n",
    "    state[\"documents\"]\n",
    "\n",
    "    if web_search == \"Yes\":\n",
    "        # All documents have been filtered check_relevance\n",
    "        # We will re-generate a new query\n",
    "        print(\n",
    "            \"---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY---\"\n",
    "        )\n",
    "        return \"transform_query\"\n",
    "    else:\n",
    "        # We have relevant documents, so generate answer\n",
    "        print(\"---DECISION: GENERATE---\")\n",
    "        return \"generate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "38219e5a-28ab-4e7a-b742-75241917dc52",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-09T07:26:47.550136Z",
     "iopub.status.busy": "2024-07-09T07:26:47.549709Z",
     "iopub.status.idle": "2024-07-09T07:26:47.558260Z",
     "shell.execute_reply": "2024-07-09T07:26:47.557739Z",
     "shell.execute_reply.started": "2024-07-09T07:26:47.550107Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph, START\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Define the nodes\n",
    "workflow.add_node(\"retrieve\", retrieve)  # retrieve\n",
    "workflow.add_node(\"grade_documents\", grade_documents)  # grade documents\n",
    "workflow.add_node(\"generate\", generate)  # generatae\n",
    "workflow.add_node(\"transform_query\", transform_query)  # transform_query\n",
    "workflow.add_node(\"web_search_node\", web_search)  # web search\n",
    "\n",
    "# Build graph\n",
    "workflow.add_edge(START, \"retrieve\")\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    decide_to_generate,\n",
    "    {\n",
    "        \"transform_query\": \"transform_query\",\n",
    "        \"generate\": \"generate\",\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"transform_query\", \"web_search_node\")\n",
    "workflow.add_edge(\"web_search_node\", \"generate\")\n",
    "workflow.add_edge(\"generate\", END)\n",
    "# Compile\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "33769774-d55b-4734-9532-8d573338c292",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-09T07:32:13.504693Z",
     "iopub.status.busy": "2024-07-09T07:32:13.504349Z",
     "iopub.status.idle": "2024-07-09T07:32:26.422239Z",
     "shell.execute_reply": "2024-07-09T07:32:26.421753Z",
     "shell.execute_reply.started": "2024-07-09T07:32:13.504672Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---RETRIEVE---\n",
      "\"Node 'retrieve':\"\n",
      "\n",
      "---\n",
      "\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "binary_score='yes'\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "binary_score='yes'\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "binary_score='no'\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY---\n",
      "\"Node 'grade_documents':\"\n",
      "\n",
      "---\n",
      "\n",
      "---TRANSFORM QUERY---\n",
      "\"Node 'transform_query':\"\n",
      "\n",
      "---\n",
      "\n",
      "---WEB SEARCH---\n",
      "\"Node 'web_search_node':\"\n",
      "\n",
      "---\n",
      "\n",
      "---GENERATE---\n",
      "\"Node 'generate':\"\n",
      "\n",
      "---\n",
      "\n",
      "('The key phenotypic traits of high-yielding soybean varieties include reduced '\n",
      " 'plant height to minimize lodging. These varieties also exhibit stress '\n",
      " 'tolerance, as stress during growth stages can significantly decrease yield. '\n",
      " 'However, simply reducing plant height is unlikely to directly increase yield '\n",
      " \"due to soybean's multiple pod formation nodes.\")\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# Run\n",
    "inputs = {\"question\": \"Phenotypically, what are the characteristics of high-yielding soybeans, such as growth rate?\"}\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        # Node\n",
    "        pprint(f\"Node '{key}':\")\n",
    "        # Optional: print full state at each node\n",
    "        # pprint.pprint(value[\"keys\"], indent=2, width=80, depth=None)\n",
    "    print(\"\\n---\\n\")\n",
    "\n",
    "# Final generation\n",
    "pprint(value[\"generation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6769f03f-f36b-4475-b7a6-b73d0cb98268",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
