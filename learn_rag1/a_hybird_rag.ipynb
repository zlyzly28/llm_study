{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7d783ac-ca58-4165-a2f9-9762ae6258ac",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-08T07:42:01.753771Z",
     "iopub.status.busy": "2024-07-08T07:42:01.753017Z",
     "iopub.status.idle": "2024-07-08T07:42:21.866363Z",
     "shell.execute_reply": "2024-07-08T07:42:21.865831Z",
     "shell.execute_reply.started": "2024-07-08T07:42:01.753738Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['id', 'source', 'page', 'question', 'ground_truth', 'context'])\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.schema import Document\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm, trange\n",
    "from retiever_eval_list import get_result_retrieva, get_retriever_res_list\n",
    "import os\n",
    "import shutil\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "documents = []\n",
    "dc_name = [\"soybean_konw.pdf\", \"soybean2.pdf\"]\n",
    "for tmp_name in dc_name:\n",
    "    # print(len(PyPDFLoader(tmp_name).load()))\n",
    "    documents += PyPDFLoader(tmp_name).load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=200)\n",
    "texts = text_splitter.split_documents(documents[:])\n",
    "for idx, text in enumerate(texts):\n",
    "    text.metadata[\"id\"] = idx\n",
    "\n",
    "df = pd.read_excel('soybean_q_gt_609.xlsx', sheet_name='Sheet1')\n",
    "\n",
    "# 修改\n",
    "folder_path = 'Result/a_hybird_rag/'\n",
    "retriever_filename = \"Result/a_hybird_rag/retriever_result.json\"\n",
    "save_info_result_filename = \"Result/a_hybird_rag/save_info_result.json\"\n",
    "top_k = 10\n",
    "s_index = 10\n",
    "\n",
    "model_name = '/mnt/workspace/.cache/modelscope/hub/maple77/zpoint_large_embedding_zh'\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': True}\n",
    "hf = HuggingFaceBgeEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")\n",
    "vectorstore = Chroma(persist_directory=\"soybean_db2\", embedding_function=hf)\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": top_k}\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('/mnt/workspace/.cache/modelscope/hub/Xorbits/bge-reranker-base')\n",
    "rerank_model = AutoModelForSequenceClassification.from_pretrained('/mnt/workspace/.cache/modelscope/hub/Xorbits/bge-reranker-base')\n",
    "\n",
    "\n",
    "\n",
    "def create_folder_if_not_exists(folder_path):\n",
    "    # 检查文件夹是否存在\n",
    "    if os.path.exists(folder_path):\n",
    "        # 如果存在，则删除原文件夹及其中内容\n",
    "        shutil.rmtree(folder_path)\n",
    "        print(f\"Folder '{folder_path}' existed and has been removed.\")\n",
    "    # 创建新文件夹\n",
    "    os.makedirs(folder_path)\n",
    "    print(f\"Folder '{folder_path}' has been created.\")\n",
    "\n",
    "# 打印DataFrame的内容\n",
    "column_lists = {col: df[col].tolist() for col in df.columns}\n",
    "print(column_lists.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac0354e7-099c-4395-b1ad-9d43923a7d99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T07:43:29.746511Z",
     "iopub.status.busy": "2024-07-08T07:43:29.746166Z",
     "iopub.status.idle": "2024-07-08T07:49:57.035861Z",
     "shell.execute_reply": "2024-07-08T07:49:57.034904Z",
     "shell.execute_reply.started": "2024-07-08T07:43:29.746489Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Get retriever result: 100%|██████████| 10/10 [06:27<00:00, 38.73s/it]\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "bm25_retriever = BM25Retriever.from_documents(\n",
    "    documents=texts\n",
    ")\n",
    "bm25_retriever.k = top_k\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, retriever], weights=[0.5, 0.5]\n",
    ")\n",
    "retriever_result = []\n",
    "for tmp_q in tqdm(range(len(column_lists['question'][:s_index])), desc='Get retriever result'):\n",
    "    # print(tmp_q)\n",
    "    retriever_result.append(ensemble_retriever.invoke(column_lists['question'][tmp_q]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3b6a694-4d9f-4758-b582-2820b1f9561d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T07:49:57.037982Z",
     "iopub.status.busy": "2024-07-08T07:49:57.037480Z",
     "iopub.status.idle": "2024-07-08T07:54:12.007888Z",
     "shell.execute_reply": "2024-07-08T07:54:11.934956Z",
     "shell.execute_reply.started": "2024-07-08T07:49:57.037940Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rerank result: 100%|██████████| 10/10 [04:14<00:00, 25.49s/it]\n"
     ]
    }
   ],
   "source": [
    "question_rerank_result = []\n",
    "for query_idx in trange(len(column_lists['question'][:s_index]), desc='Rerank result'):\n",
    "    pairs = []\n",
    "    for idx in range(len(retriever_result[query_idx])):\n",
    "        pairs.append([column_lists['question'][:s_index][query_idx], retriever_result[query_idx][idx].page_content])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer(pairs, padding=True, truncation=True, return_tensors='pt', max_length=512)\n",
    "        scores = rerank_model(**inputs, return_dict=True).logits.view(-1, ).float()\n",
    "    combined = sorted(zip(scores, retriever_result[query_idx]), reverse=True)\n",
    "    scores_rerank_list, retri_rerank_list = zip(*combined)\n",
    "    # print(scores_rerank_list, retri_rerank_list)\n",
    "    question_rerank_result.append(retri_rerank_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f725329f-0394-40bb-93c9-47446c6771ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T07:54:31.170666Z",
     "iopub.status.busy": "2024-07-08T07:54:31.170319Z",
     "iopub.status.idle": "2024-07-08T07:54:31.176117Z",
     "shell.execute_reply": "2024-07-08T07:54:31.175561Z",
     "shell.execute_reply.started": "2024-07-08T07:54:31.170646Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder 'Result/a_hybird_rag/' has been created.\n",
      "完成!\n"
     ]
    }
   ],
   "source": [
    "col_id = column_lists['id'][:s_index]\n",
    "rerank_result = get_result_retrieva(col_id, question_rerank_result, topk=top_k)\n",
    "# 用你想要的路径替换'your_folder_path'\n",
    "create_folder_if_not_exists(folder_path)\n",
    "# 对结果进行保存\n",
    "# 指定你想要保存的文件名\n",
    "# 使用json.dump()将字典保存为json文件\n",
    "with open(retriever_filename, 'w', encoding='utf-8') as f:\n",
    "    json.dump(rerank_result, f, ensure_ascii=False, indent=4)\n",
    "print('完成!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3033102c-bf70-40bc-9e6b-01e20d5ade2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T08:52:29.614462Z",
     "iopub.status.busy": "2024-07-08T08:52:29.614092Z",
     "iopub.status.idle": "2024-07-08T08:52:29.620234Z",
     "shell.execute_reply": "2024-07-08T08:52:29.619563Z",
     "shell.execute_reply.started": "2024-07-08T08:52:29.614440Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "完成!\n"
     ]
    }
   ],
   "source": [
    "# dict_keys(['id', 'source', 'page', 'question', 'ground_truth', 'context'])\n",
    "# column_lists['context'][:s_index]\n",
    "save_info_result = {}\n",
    "save_info_result['id'] = column_lists['id'][:s_index]\n",
    "save_info_result['source'] = column_lists['source'][:s_index]\n",
    "save_info_result['page'] = column_lists['page'][:s_index]\n",
    "save_info_result['question'] = column_lists['question'][:s_index]\n",
    "save_info_result['ground_truth'] = column_lists['ground_truth'][:s_index]\n",
    "save_info_result['context'] = column_lists['context'][:s_index]\n",
    "save_info_result['retriever_result_list'] = get_retriever_res_list(retriever_result, top_k)\n",
    "\n",
    "# 使用json.dump()将字典保存为json文件\n",
    "with open(save_info_result_filename, 'w', encoding='utf-8') as f:\n",
    "    json.dump(save_info_result, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print('完成!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
