{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d28da69-b09e-4ebf-a8df-1630b3313811",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T08:33:23.439181Z",
     "iopub.status.busy": "2024-07-10T08:33:23.438669Z",
     "iopub.status.idle": "2024-07-10T08:33:26.050420Z",
     "shell.execute_reply": "2024-07-10T08:33:26.049427Z",
     "shell.execute_reply.started": "2024-07-10T08:33:23.439141Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m dc_name \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoybean_konw.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoybean2.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tmp_name \u001b[38;5;129;01min\u001b[39;00m dc_name:\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# print(len(PyPDFLoader(tmp_name).load()))\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m     documents \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mPyPDFLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtmp_name\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m text_splitter \u001b[38;5;241m=\u001b[39m RecursiveCharacterTextSplitter(chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, chunk_overlap\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m)\n\u001b[1;32m     14\u001b[0m texts \u001b[38;5;241m=\u001b[39m text_splitter\u001b[38;5;241m.\u001b[39msplit_documents(documents[:])\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/langchain_core/document_loaders/base.py:29\u001b[0m, in \u001b[0;36mBaseLoader.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[1;32m     28\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load data into Document objects.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlazy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/langchain_community/document_loaders/pdf.py:193\u001b[0m, in \u001b[0;36mPyPDFLoader.lazy_load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    192\u001b[0m     blob \u001b[38;5;241m=\u001b[39m Blob\u001b[38;5;241m.\u001b[39mfrom_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path)  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m--> 193\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/langchain_core/document_loaders/base.py:125\u001b[0m, in \u001b[0;36mBaseBlobParser.parse\u001b[0;34m(self, blob)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m, blob: Blob) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[1;32m    111\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Eagerly parse the blob into a document or documents.\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    This is a convenience method for interactive development environment.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;124;03m        List of documents\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlazy_parse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/langchain_community/document_loaders/parsers/pdf.py:102\u001b[0m, in \u001b[0;36mPyPDFParser.lazy_parse\u001b[0;34m(self, blob)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m blob\u001b[38;5;241m.\u001b[39mas_bytes_io() \u001b[38;5;28;01mas\u001b[39;00m pdf_file_obj:  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     pdf_reader \u001b[38;5;241m=\u001b[39m pypdf\u001b[38;5;241m.\u001b[39mPdfReader(pdf_file_obj, password\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpassword)\n\u001b[0;32m--> 102\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m [\n\u001b[1;32m    103\u001b[0m         Document(\n\u001b[1;32m    104\u001b[0m             page_content\u001b[38;5;241m=\u001b[39mpage\u001b[38;5;241m.\u001b[39mextract_text()\n\u001b[1;32m    105\u001b[0m             \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extract_images_from_page(page),\n\u001b[1;32m    106\u001b[0m             metadata\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: blob\u001b[38;5;241m.\u001b[39msource, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpage\u001b[39m\u001b[38;5;124m\"\u001b[39m: page_number},  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    107\u001b[0m         )\n\u001b[1;32m    108\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m page_number, page \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(pdf_reader\u001b[38;5;241m.\u001b[39mpages)\n\u001b[1;32m    109\u001b[0m     ]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/langchain_community/document_loaders/parsers/pdf.py:104\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m blob\u001b[38;5;241m.\u001b[39mas_bytes_io() \u001b[38;5;28;01mas\u001b[39;00m pdf_file_obj:  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     pdf_reader \u001b[38;5;241m=\u001b[39m pypdf\u001b[38;5;241m.\u001b[39mPdfReader(pdf_file_obj, password\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpassword)\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m [\n\u001b[1;32m    103\u001b[0m         Document(\n\u001b[0;32m--> 104\u001b[0m             page_content\u001b[38;5;241m=\u001b[39m\u001b[43mpage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m             \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extract_images_from_page(page),\n\u001b[1;32m    106\u001b[0m             metadata\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: blob\u001b[38;5;241m.\u001b[39msource, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpage\u001b[39m\u001b[38;5;124m\"\u001b[39m: page_number},  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    107\u001b[0m         )\n\u001b[1;32m    108\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m page_number, page \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(pdf_reader\u001b[38;5;241m.\u001b[39mpages)\n\u001b[1;32m    109\u001b[0m     ]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pypdf/_page.py:2083\u001b[0m, in \u001b[0;36mPageObject.extract_text\u001b[0;34m(self, orientations, space_width, visitor_operand_before, visitor_operand_after, visitor_text, extraction_mode, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2080\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(orientations, \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m   2081\u001b[0m     orientations \u001b[38;5;241m=\u001b[39m (orientations,)\n\u001b[0;32m-> 2083\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extract_text\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2084\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2085\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2086\u001b[0m \u001b[43m    \u001b[49m\u001b[43morientations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2087\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspace_width\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2088\u001b[0m \u001b[43m    \u001b[49m\u001b[43mPG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCONTENTS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2089\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvisitor_operand_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2090\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvisitor_operand_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2091\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvisitor_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2092\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pypdf/_page.py:1593\u001b[0m, in \u001b[0;36mPageObject._extract_text\u001b[0;34m(self, obj, pdf, orientations, space_width, content_key, visitor_operand_before, visitor_operand_after, visitor_text)\u001b[0m\n\u001b[1;32m   1591\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Font\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resources_dict:\n\u001b[1;32m   1592\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m cast(DictionaryObject, resources_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Font\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[0;32m-> 1593\u001b[0m         cmaps[f] \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_char_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspace_width\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1594\u001b[0m cmap: Tuple[\n\u001b[1;32m   1595\u001b[0m     Union[\u001b[38;5;28mstr\u001b[39m, Dict[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m]], Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m], \u001b[38;5;28mstr\u001b[39m, Optional[DictionaryObject]\n\u001b[1;32m   1596\u001b[0m ] \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1600\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1601\u001b[0m )  \u001b[38;5;66;03m# (encoding,CMAP,font resource name,dictionary-object of font)\u001b[39;00m\n\u001b[1;32m   1602\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pypdf/_cmap.py:32\u001b[0m, in \u001b[0;36mbuild_char_map\u001b[0;34m(font_name, space_width, obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_char_map\u001b[39m(\n\u001b[1;32m     18\u001b[0m     font_name: \u001b[38;5;28mstr\u001b[39m, space_width: \u001b[38;5;28mfloat\u001b[39m, obj: DictionaryObject\n\u001b[1;32m     19\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mfloat\u001b[39m, Union[\u001b[38;5;28mstr\u001b[39m, Dict[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m]], Dict[Any, Any], DictionaryObject]:\n\u001b[1;32m     20\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124;03m    Determine information about a font.\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03m        The font-dictionary itself is suitable for the curious.\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m     ft: DictionaryObject \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/Resources\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/Font\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfont_name\u001b[49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     33\u001b[0m     font_subtype, font_halfspace, font_encoding, font_map \u001b[38;5;241m=\u001b[39m build_char_map_from_dict(\n\u001b[1;32m     34\u001b[0m         space_width, ft\n\u001b[1;32m     35\u001b[0m     )\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m font_subtype, font_halfspace, font_encoding, font_map, ft\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pypdf/generic/_data_structures.py:409\u001b[0m, in \u001b[0;36mDictionaryObject.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PdfObject:\n\u001b[0;32m--> 409\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mdict\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pypdf/generic/_base.py:284\u001b[0m, in \u001b[0;36mIndirectObject.get_object\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_object\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPdfObject\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_object\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pypdf/_reader.py:420\u001b[0m, in \u001b[0;36mPdfReader.get_object\u001b[0;34m(self, indirect_reference)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrict:\n\u001b[1;32m    419\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m generation \u001b[38;5;241m==\u001b[39m indirect_reference\u001b[38;5;241m.\u001b[39mgeneration\n\u001b[0;32m--> 420\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[43mread_object\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;66;03m# override encryption is used for the /Encrypt dictionary\u001b[39;00m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_override_encryption \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encryption \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    424\u001b[0m     \u001b[38;5;66;03m# if we don't have the encryption key:\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pypdf/generic/_data_structures.py:1282\u001b[0m, in \u001b[0;36mread_object\u001b[0;34m(stream, pdf, forced_encoding)\u001b[0m\n\u001b[1;32m   1279\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m tok \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1280\u001b[0m     \u001b[38;5;66;03m# hexadecimal string OR dictionary\u001b[39;00m\n\u001b[1;32m   1281\u001b[0m     peek \u001b[38;5;241m=\u001b[39m stream\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m-> 1282\u001b[0m     \u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseek\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# reset to start\u001b[39;00m\n\u001b[1;32m   1283\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m peek \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<<\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1284\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m DictionaryObject\u001b[38;5;241m.\u001b[39mread_from_stream(stream, pdf, forced_encoding)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "documents = []\n",
    "dc_name = [\"soybean_konw.pdf\", \"soybean2.pdf\"]\n",
    "for tmp_name in dc_name:\n",
    "    # print(len(PyPDFLoader(tmp_name).load()))\n",
    "    documents += PyPDFLoader(tmp_name).load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=200)\n",
    "texts = text_splitter.split_documents(documents[:])\n",
    "for idx, text in enumerate(texts):\n",
    "    text.metadata[\"id\"] = idx\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.schema import Document\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n",
    "top_k = 10\n",
    "\n",
    "model_name = '/mnt/workspace/.cache/modelscope/hub/maple77/zpoint_large_embedding_zh'\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': True}\n",
    "hf = HuggingFaceBgeEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")\n",
    "vectorstore = Chroma(persist_directory=\"soybean_db2\", embedding_function=hf)\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": top_k}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55a25cc5-c89f-463a-a29b-73f2f16cc29c",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-10T10:42:54.424182Z",
     "iopub.status.busy": "2024-07-10T10:42:54.423790Z",
     "iopub.status.idle": "2024-07-10T10:42:54.879630Z",
     "shell.execute_reply": "2024-07-10T10:42:54.878971Z",
     "shell.execute_reply.started": "2024-07-10T10:42:54.424161Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def exponentiate(x: float, y: float) -> float:\n",
    "    \"\"\"Raise 'x' to the 'y'.\"\"\"\n",
    "    return x**y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dee8169-b18a-4666-838a-4c287e25a2b8",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-10T10:42:56.134996Z",
     "iopub.status.busy": "2024-07-10T10:42:56.134567Z",
     "iopub.status.idle": "2024-07-10T10:42:56.138028Z",
     "shell.execute_reply": "2024-07-10T10:42:56.137497Z",
     "shell.execute_reply.started": "2024-07-10T10:42:56.134974Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tools = [exponentiate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fcc0c3e-1d0d-47b4-97a4-6b4ed2d2bc88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T10:42:58.137095Z",
     "iopub.status.busy": "2024-07-10T10:42:58.136699Z",
     "iopub.status.idle": "2024-07-10T10:43:00.056170Z",
     "shell.execute_reply": "2024-07-10T10:43:00.055597Z",
     "shell.execute_reply.started": "2024-07-10T10:42:58.137074Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "You are a helpful assistant.\n",
      "\n",
      "=============================\u001b[1m Messages Placeholder \u001b[0m=============================\n",
      "\n",
      "\u001b[33;1m\u001b[1;3m{{messages}}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# Get the prompt to use - you can modify this!\n",
    "prompt = hub.pull(\"wfh/react-agent-executor\")\n",
    "prompt.pretty_print()\n",
    "\n",
    "# Choose the LLM that will drive the agent\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.6,\n",
    "    model=\"glm-4-0520\",\n",
    "    openai_api_key=\"661a7aa0aeb8ca129eb4647461123230.bl9w581QKpnMfBvs\",\n",
    "    openai_api_base=\"https://open.bigmodel.cn/api/paas/v4/\"\n",
    ")\n",
    "agent_executor = create_react_agent(llm, tools, messages_modifier=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97286fed-aee2-4f5e-a699-84b5c699ea14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T10:43:35.591959Z",
     "iopub.status.busy": "2024-07-10T10:43:35.591097Z",
     "iopub.status.idle": "2024-07-10T10:43:37.462863Z",
     "shell.execute_reply": "2024-07-10T10:43:37.462300Z",
     "shell.execute_reply.started": "2024-07-10T10:43:35.591914Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='what is 3 ** 12?', id='4d2ec882-4b70-4830-ac17-2d2f44976848'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_8827320252104390940', 'function': {'arguments': '{\"x\": 3, \"y\": 12}', 'name': 'exponentiate'}, 'type': 'function', 'index': 0}]}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 136, 'total_tokens': 153}, 'model_name': 'glm-4-0520', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-e2fc84c7-a138-4932-9329-07b0df884633-0', tool_calls=[{'name': 'exponentiate', 'args': {'x': 3, 'y': 12}, 'id': 'call_8827320252104390940'}], usage_metadata={'input_tokens': 136, 'output_tokens': 17, 'total_tokens': 153}),\n",
       "  ToolMessage(content='531441.0', name='exponentiate', id='88d8d3d8-489a-4ff5-8cb6-0446e9b2eff7', tool_call_id='call_8827320252104390940'),\n",
       "  AIMessage(content='3 ** 12 is 531441.0.', response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 163, 'total_tokens': 178}, 'model_name': 'glm-4-0520', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-75dbf74f-3652-4eff-a9e2-41e6e6658073-0', usage_metadata={'input_tokens': 163, 'output_tokens': 15, 'total_tokens': 178})]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"messages\": [(\"user\", \"what is 3 ** 12?\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c4ed282-142c-4231-897d-d2664fee175b",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-10T10:43:41.895909Z",
     "iopub.status.busy": "2024-07-10T10:43:41.895546Z",
     "iopub.status.idle": "2024-07-10T10:43:41.899592Z",
     "shell.execute_reply": "2024-07-10T10:43:41.899075Z",
     "shell.execute_reply.started": "2024-07-10T10:43:41.895889Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated, List, Tuple, TypedDict\n",
    "\n",
    "\n",
    "class PlanExecute(TypedDict):\n",
    "    input: str\n",
    "    plan: List[str]\n",
    "    past_steps: Annotated[List[List], operator.add]\n",
    "    response: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43f001d8-ee13-4715-b085-8c186f3416ee",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-10T10:43:43.285680Z",
     "iopub.status.busy": "2024-07-10T10:43:43.285270Z",
     "iopub.status.idle": "2024-07-10T10:43:43.290466Z",
     "shell.execute_reply": "2024-07-10T10:43:43.289851Z",
     "shell.execute_reply.started": "2024-07-10T10:43:43.285657Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "\n",
    "class Plan(BaseModel):\n",
    "    \"\"\"Plan to follow in future\"\"\"\n",
    "\n",
    "    steps1: str = Field(\n",
    "        ...,\n",
    "        description=\"Step 1: The different steps to be followed should be arranged in order. If you feel that you no longer need to customize the steps, return to no.\"\n",
    "    )\n",
    "    steps2: str = Field(\n",
    "        ...,\n",
    "        description=\"Step 2: The different steps to be followed should be arranged in order. If you feel that you no longer need to customize the steps, return to no.\"\n",
    "    )\n",
    "    steps3: str = Field(\n",
    "        ...,\n",
    "        description=\"Step 3: The different steps to be followed should be arranged in order. If you feel that you no longer need to customize the steps, return to no.\"\n",
    "    )\n",
    "parser = PydanticOutputParser(pydantic_object=Plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fabea44-ef8e-4444-89b5-2b65b95fc54e",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-10T10:43:46.422734Z",
     "iopub.status.busy": "2024-07-10T10:43:46.422361Z",
     "iopub.status.idle": "2024-07-10T10:43:46.516921Z",
     "shell.execute_reply": "2024-07-10T10:43:46.516313Z",
     "shell.execute_reply.started": "2024-07-10T10:43:46.422712Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "planner_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"For the given objective, come up with a simple step by step plan. \\\n",
    "This plan should involve individual tasks, that if executed correctly will yield the correct answer. Do not add any superfluous steps. \\\n",
    "The result of the final step should be the final answer. Make sure that each step has all the information needed - do not skip steps.\n",
    "Answer the user query. Wrap the output in `json` tags\\n{format_instructions}\"\"\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ").partial(format_instructions=parser.get_format_instructions())\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.6,\n",
    "    model=\"glm-4-0520\",\n",
    "    openai_api_key=\"661a7aa0aeb8ca129eb4647461123230.bl9w581QKpnMfBvs\",\n",
    "    openai_api_base=\"https://open.bigmodel.cn/api/paas/v4/\"\n",
    ")\n",
    "\n",
    "planner = planner_prompt | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2929bf8a-f327-486c-bbcd-a0c000345aac",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-10T10:46:00.171624Z",
     "iopub.status.busy": "2024-07-10T10:46:00.171204Z",
     "iopub.status.idle": "2024-07-10T10:46:16.248811Z",
     "shell.execute_reply": "2024-07-10T10:46:16.248233Z",
     "shell.execute_reply.started": "2024-07-10T10:46:00.171601Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Plan(steps1=\"Import the necessary libraries, including pandas for data manipulation, sklearn's datasets to load the iris data, train_test_split to split the dataset, and a regression model like LinearRegression.\", steps2=\"Load the iris dataset using sklearn's datasets module.\", steps3='Separate the features (X) from the target variable (y), and then split them into training and test sets using the train_test_split function.')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "planner.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            (\"user\", \"Task decomposition and Load the iris dataset and write the code for sklearn machine learning regression?\")\n",
    "        ]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb03d93d-f01b-4ca2-a9ad-5ae4d0f55b1b",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-10T10:48:52.218284Z",
     "iopub.status.busy": "2024-07-10T10:48:52.217892Z",
     "iopub.status.idle": "2024-07-10T10:48:52.222905Z",
     "shell.execute_reply": "2024-07-10T10:48:52.222366Z",
     "shell.execute_reply.started": "2024-07-10T10:48:52.218264Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "\n",
    "class Response(BaseModel):\n",
    "    \"\"\"Response to user.\"\"\"\n",
    "\n",
    "    response: str\n",
    "\n",
    "\n",
    "class Act(BaseModel):\n",
    "    \"\"\"Action to perform.\"\"\"\n",
    "\n",
    "    action: Union[Response, Plan] = Field(\n",
    "        description=\"Action to perform. If you want to respond to user, use Response. \"\n",
    "        \"If you need to further use tools to get the answer, use Plan.\"\n",
    "    )\n",
    "parser2 = PydanticOutputParser(pydantic_object=Act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da087ddf-9e43-4ce2-b53d-2f7aa8ca8d81",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-10T10:48:53.565210Z",
     "iopub.status.busy": "2024-07-10T10:48:53.564723Z",
     "iopub.status.idle": "2024-07-10T10:48:53.711596Z",
     "shell.execute_reply": "2024-07-10T10:48:53.710850Z",
     "shell.execute_reply.started": "2024-07-10T10:48:53.565178Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "replanner_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"For the given objective, come up with a simple step by step plan. \\\n",
    "    This plan should involve individual tasks, that if executed correctly will yield the correct answer. Do not add any superfluous steps. \\\n",
    "    The result of the final step should be the final answer. Make sure that each step has all the information needed - do not skip steps.\n",
    "\n",
    "    Your objective was this:\n",
    "    {input}\n",
    "\n",
    "    Your original plan was this:\n",
    "    {plan}\n",
    "\n",
    "    You have currently done the follow steps:\n",
    "    {past_steps}\n",
    "\n",
    "    Update your plan accordingly. If no more steps are needed and you can return to the user, then respond with that. \n",
    "    Otherwise, fill out the plan. Only add steps to the plan that still NEED to be done. Do not return previously done steps as part of the plan.\n",
    "    Complete the plan quickly and succinctly. Don't make too many plans.\n",
    "    Answer the user query. Wrap the output in `json` tags\\n{format_instructions}\"\"\"\n",
    ").partial(format_instructions=parser2.get_format_instructions())\n",
    "\n",
    "\n",
    "# replanner = replanner_prompt | ChatOpenAI(\n",
    "#     model=\"gpt-4o\", temperature=0\n",
    "# ).with_structured_output(Act)\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.6,\n",
    "    model=\"glm-4-0520\",\n",
    "    openai_api_key=\"661a7aa0aeb8ca129eb4647461123230.bl9w581QKpnMfBvs\",\n",
    "    openai_api_base=\"https://open.bigmodel.cn/api/paas/v4/\"\n",
    ")\n",
    "\n",
    "replanner = replanner_prompt | llm | parser2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4542d6d-fa16-41ef-bf76-298bca2ee529",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-10T10:48:56.653271Z",
     "iopub.status.busy": "2024-07-10T10:48:56.652770Z",
     "iopub.status.idle": "2024-07-10T10:48:56.663209Z",
     "shell.execute_reply": "2024-07-10T10:48:56.662527Z",
     "shell.execute_reply.started": "2024-07-10T10:48:56.653236Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "\n",
    "async def execute_step(state: PlanExecute):\n",
    "    plan = state[\"plan\"]\n",
    "    plan_str = \"\\n\".join(f\"{i+1}. {step}\" for i, step in enumerate(plan))\n",
    "    # print(plan_str)\n",
    "    task = plan[0]\n",
    "    task_formatted = f\"\"\"For the following plan:\n",
    "{plan_str}\\n\\nYou are tasked with executing step {1}, {task}.\"\"\"\n",
    "    agent_response = await agent_executor.ainvoke(\n",
    "        {\"messages\": [(\"user\", task_formatted)]}\n",
    "    )\n",
    "    return {\n",
    "        \"past_steps\": [task, agent_response[\"messages\"][-1].content],\n",
    "    }\n",
    "\n",
    "\n",
    "async def plan_step(state: PlanExecute):\n",
    "    plan = await planner.ainvoke({\"messages\": [(\"user\", state[\"input\"])]})\n",
    "    \n",
    "    return {\"plan\": [plan.steps1, plan.steps2, plan.steps3]}\n",
    "\n",
    "\n",
    "async def replan_step(state: PlanExecute):\n",
    "    print('\\n现在进行重新规划\\n')\n",
    "    # print(state)\n",
    "    \n",
    "    output = await replanner.ainvoke(state)\n",
    "    print('\\n现在输出重新规划结果\\n')\n",
    "    print(output)\n",
    "    if isinstance(output.action, Response):\n",
    "        return {\"response\": output.action.response}\n",
    "    else:\n",
    "        z = [output.action.steps1, output.action.steps2, output.action.steps3]\n",
    "        return {\"plan\": [j for j in z if 'no' not in j.lower()]}\n",
    "\n",
    "\n",
    "def should_end(state: PlanExecute) -> Literal[\"agent\", \"__end__\"]:\n",
    "    if \"response\" in state and state[\"response\"]:\n",
    "        return \"__end__\"\n",
    "    else:\n",
    "        return \"agent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d7e7189-6cce-4d4a-9347-2db9069e349f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T10:48:58.679521Z",
     "iopub.status.busy": "2024-07-10T10:48:58.679066Z",
     "iopub.status.idle": "2024-07-10T10:48:58.687557Z",
     "shell.execute_reply": "2024-07-10T10:48:58.686914Z",
     "shell.execute_reply.started": "2024-07-10T10:48:58.679493Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START\n",
    "\n",
    "workflow = StateGraph(PlanExecute)\n",
    "\n",
    "# Add the plan node\n",
    "workflow.add_node(\"planner\", plan_step)\n",
    "\n",
    "# Add the execution step\n",
    "workflow.add_node(\"agent\", execute_step)\n",
    "\n",
    "# Add a replan node\n",
    "workflow.add_node(\"replan\", replan_step)\n",
    "\n",
    "workflow.add_edge(START, \"planner\")\n",
    "\n",
    "# From plan we go to agent\n",
    "workflow.add_edge(\"planner\", \"agent\")\n",
    "\n",
    "# From agent, we replan\n",
    "workflow.add_edge(\"agent\", \"replan\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"replan\",\n",
    "    # Next, we pass in the function that will determine which node is called next.\n",
    "    should_end,\n",
    ")\n",
    "\n",
    "# Finally, we compile it!\n",
    "# This compiles it into a LangChain Runnable,\n",
    "# meaning you can use it as you would any other runnable\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a35eabe-931e-4f4f-84de-8b31342f045c",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(app.get_graph(xray=False).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8922064c-da7c-42ad-8d44-95d04a00737c",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-10T10:49:09.395585Z",
     "iopub.status.busy": "2024-07-10T10:49:09.395125Z",
     "iopub.status.idle": "2024-07-10T10:50:35.041732Z",
     "shell.execute_reply": "2024-07-10T10:50:35.040859Z",
     "shell.execute_reply.started": "2024-07-10T10:49:09.395556Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "————————————————————————————————————————————————当前的K\n",
      "planner\n",
      "————————————————————————————————————————————————当前的V\n",
      "{'plan': ['Define the individual tasks to answer the user query.', 'Arrange the tasks in a logical order.', 'Format the arranged tasks as a JSON object that fits the given schema.']}\n",
      "————————————————————————————————————————————————当前的K\n",
      "agent\n",
      "————————————————————————————————————————————————当前的V\n",
      "{'past_steps': ['Define the individual tasks to answer the user query.', \"To execute step 1, we first need to understand the user query. However, you haven't provided the specific user query we need to answer. Could you please provide the user query that we need to break down into individual tasks?\"]}\n",
      "\n",
      "现在进行重新规划\n",
      "\n",
      "\n",
      "现在输出重新规划结果\n",
      "\n",
      "action=Plan(steps1='Import the necessary libraries.', steps2='Load the iris dataset using sklearn.', steps3='Create a machine learning regression model using sklearn.')\n",
      "————————————————————————————————————————————————当前的K\n",
      "replan\n",
      "————————————————————————————————————————————————当前的V\n",
      "{'plan': ['Import the necessary libraries.', 'Load the iris dataset using sklearn.', 'Create a machine learning regression model using sklearn.']}\n",
      "————————————————————————————————————————————————当前的K\n",
      "agent\n",
      "————————————————————————————————————————————————当前的V\n",
      "{'past_steps': ['Import the necessary libraries.', \"To execute step 1, which is to import the necessary libraries for the given plan, you would typically need to import the following libraries in Python using `sklearn` (also known as `scikit-learn`) for the iris dataset and creating a machine learning model. Here is the code snippet that accomplishes this:\\n\\n```python\\n# Import necessary libraries\\nfrom sklearn.datasets import load_iris\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\\n```\\n\\nIn this snippet, we're importing:\\n\\n- `load_iris` to load the iris dataset.\\n- `train_test_split` to split the dataset into training and testing sets.\\n- `LogisticRegression` as the regression model, which is suitable for classification tasks like the iris dataset.\\n- `accuracy_score`, `confusion_matrix`, and `classification_report` for evaluating the model's performance once it's been trained.\\n\\nNote that even though the task mentioned creating a regression model, the iris dataset is a classification problem. Hence, `LogisticRegression` is used, which is actually a classification algorithm despite its name. If you intended to use a true regression model, you would import a different estimator, such as `LinearRegression`. However, since the iris dataset is for classification, `LogisticRegression` is the appropriate choice.\"]}\n",
      "\n",
      "现在进行重新规划\n",
      "\n",
      "\n",
      "现在输出重新规划结果\n",
      "\n",
      "action=Plan(steps1='Load the iris dataset using sklearn.', steps2='Split the dataset into features (X) and target (y).', steps3='Create a machine learning regression model using sklearn and train it on the dataset.')\n",
      "————————————————————————————————————————————————当前的K\n",
      "replan\n",
      "————————————————————————————————————————————————当前的V\n",
      "{'plan': ['Load the iris dataset using sklearn.', 'Split the dataset into features (X) and target (y).', 'Create a machine learning regression model using sklearn and train it on the dataset.']}\n",
      "————————————————————————————————————————————————当前的K\n",
      "agent\n",
      "————————————————————————————————————————————————当前的V\n",
      "{'past_steps': ['Load the iris dataset using sklearn.', \"To load the Iris dataset using `sklearn`, you would typically use the `load_iris` function from the `sklearn.datasets` module. Here's a Python code snippet that performs this action:\\n\\n```python\\nfrom sklearn.datasets import load_iris\\n\\n# Load the iris dataset\\niris = load_iris()\\n```\\n\\nThe `load_iris` function returns an object that contains the Iris dataset. This object has several attributes including `data`, `target`, `feature_names`, and `target_names`. The `data` attribute contains the features of the dataset, and `target` contains the labels associated with each sample. \\n\\nIf you were coding this in a real environment, you would not need to do anything else to complete step 1. However, since this is a text-based interaction and I can't execute code, you would need to run the provided Python snippet in your own environment to actually load the dataset.\"]}\n",
      "\n",
      "现在进行重新规划\n",
      "\n",
      "\n",
      "现在输出重新规划结果\n",
      "\n",
      "action=Plan(steps1='Split the dataset into features (X) and target (y).', steps2='Create a machine learning regression model using sklearn and train it on the dataset.', steps3='no')\n",
      "————————————————————————————————————————————————当前的K\n",
      "replan\n",
      "————————————————————————————————————————————————当前的V\n",
      "{'plan': ['Split the dataset into features (X) and target (y).', 'Create a machine learning regression model using sklearn and train it on the dataset.']}\n",
      "————————————————————————————————————————————————当前的K\n",
      "agent\n",
      "————————————————————————————————————————————————当前的V\n",
      "{'past_steps': ['Split the dataset into features (X) and target (y).', \"To execute step 1, you would need to have a dataset available. Assuming you have a dataset in a format that can be used with `pandas` (like a CSV file), you can use the `pandas` library in Python to load the dataset and then split it into features (X) and target (y).\\n\\nBelow is a generic example of how to do this in Python using the `pandas` library. Note that you'll need to adjust this code to the specifics of your dataset, such as the file name, the names of the feature columns, and the name of the target column.\\n\\n```python\\nimport pandas as pd\\n\\n# Load the dataset\\n# Replace 'data.csv' with the path to your actual data file\\ndf = pd.read_csv('data.csv')\\n\\n# Assume that all columns except 'target' are features\\n# Replace 'target' with the actual name of your target column\\nX = df.drop('target', axis=1)  # Features\\ny = df['target']  # Target\\n\\n# Now X contains the features and y contains the target\\n```\\n\\nIf you have a specific dataset and know the names of the columns, you can replace 'data.csv' and 'target' with the appropriate values for your dataset. If your target is in a different format or location within your dataset, you would need to adjust the code to accommodate that as well.\"]}\n",
      "\n",
      "现在进行重新规划\n",
      "\n",
      "\n",
      "现在输出重新规划结果\n",
      "\n",
      "action=Plan(steps1='Split the dataset into training and testing sets.', steps2='Create a Logistic Regression model and train it on the training set.', steps3='Evaluate the model on the testing set and output the performance metrics.')\n",
      "————————————————————————————————————————————————当前的K\n",
      "replan\n",
      "————————————————————————————————————————————————当前的V\n",
      "{'plan': ['Split the dataset into training and testing sets.', 'Create a Logistic Regression model and train it on the training set.', 'Evaluate the model on the testing set and output the performance metrics.']}\n",
      "————————————————————————————————————————————————当前的K\n",
      "agent\n",
      "————————————————————————————————————————————————当前的V\n",
      "{'past_steps': ['Split the dataset into training and testing sets.', \"To execute step 1, you would typically use a programming language like Python and a library such as scikit-learn, which provides a convenient function to split datasets. However, since I can't execute code, I'll guide you through the process conceptually.\\n\\nHere's how you would generally split a dataset into training and testing sets using scikit-learn:\\n\\n```python\\nfrom sklearn.model_selection import train_test_split\\n\\n# Assuming 'data' is your dataset and 'labels' are the corresponding labels\\n\\n# Define the size of the testing set (commonly 20% or 30% of the whole dataset)\\ntest_size = 0.2\\n\\n# Split the data into training and testing sets\\nX_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=test_size, random_state=42)\\n\\n# 'X_train' and 'y_train' are the training data and labels\\n# 'X_test' and 'y_test' are the testing data and labels\\n```\\n\\nThe `train_test_split` function takes the following important parameters:\\n\\n- `data`: Your feature dataset, which you want to split.\\n- `labels`: The corresponding labels for your data.\\n- `test_size`: The proportion of the dataset to include in the test split (can be a float or an integer for the number of test samples).\\n- `random_state`: Optional, controls the shuffling applied to the data before applying the split. It's useful for creating reproducible splits.\\n\\nPlease note that this is just a conceptual explanation. To actually perform the split, you would need to write and run this code in a Python environment with the necessary libraries installed.\"]}\n",
      "\n",
      "现在进行重新规划\n",
      "\n"
     ]
    },
    {
     "ename": "OutputParserException",
     "evalue": "Failed to parse Act from completion {\"action\": \"Plan\", \"steps1\": \"Split the dataset into training and testing sets.\", \"steps2\": \"Create a Logistic Regression model and train it on the training set.\", \"steps3\": \"Evaluate the model on the testing set and output the performance metrics.\"}. Got: 2 validation errors for Act\naction\n  value is not a valid dict (type=type_error.dict)\naction\n  value is not a valid dict (type=type_error.dict)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/langchain_core/output_parsers/pydantic.py:35\u001b[0m, in \u001b[0;36mPydanticOutputParser._parse_obj\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpydantic_object, pydantic\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mBaseModel):\n\u001b[0;32m---> 35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpydantic_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_obj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pydantic/v1/main.py:526\u001b[0m, in \u001b[0;36mBaseModel.parse_obj\u001b[0;34m(cls, obj)\u001b[0m\n\u001b[1;32m    525\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ValidationError([ErrorWrapper(exc, loc\u001b[38;5;241m=\u001b[39mROOT_KEY)], \u001b[38;5;28mcls\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m--> 526\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pydantic/v1/main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[0;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mValidationError\u001b[0m: 2 validation errors for Act\naction\n  value is not a valid dict (type=type_error.dict)\naction\n  value is not a valid dict (type=type_error.dict)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m config \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecursion_limit\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m15\u001b[39m}\n\u001b[1;32m      2\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTask decomposition and Load the iris dataset and write the code for sklearn machine learning regression?\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m app\u001b[38;5;241m.\u001b[39mastream(inputs, config\u001b[38;5;241m=\u001b[39mconfig):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m event\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__end__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/langgraph/pregel/__init__.py:1431\u001b[0m, in \u001b[0;36mPregel.astream\u001b[0;34m(self, input, config, stream_mode, output_keys, input_keys, interrupt_before, interrupt_after, debug)\u001b[0m\n\u001b[1;32m   1428\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m fut, task\n\u001b[1;32m   1430\u001b[0m \u001b[38;5;66;03m# panic on failure or timeout\u001b[39;00m\n\u001b[0;32m-> 1431\u001b[0m \u001b[43m_panic_or_proceed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minflight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1432\u001b[0m \u001b[38;5;66;03m# don't keep futures around in memory longer than needed\u001b[39;00m\n\u001b[1;32m   1433\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m done, inflight, futures\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/langgraph/pregel/__init__.py:1643\u001b[0m, in \u001b[0;36m_panic_or_proceed\u001b[0;34m(done, inflight, step)\u001b[0m\n\u001b[1;32m   1641\u001b[0m             inflight\u001b[38;5;241m.\u001b[39mpop()\u001b[38;5;241m.\u001b[39mcancel()\n\u001b[1;32m   1642\u001b[0m         \u001b[38;5;66;03m# raise the exception\u001b[39;00m\n\u001b[0;32m-> 1643\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m   1645\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inflight:\n\u001b[1;32m   1646\u001b[0m     \u001b[38;5;66;03m# if we got here means we timed out\u001b[39;00m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m inflight:\n\u001b[1;32m   1648\u001b[0m         \u001b[38;5;66;03m# cancel all pending tasks\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/langgraph/pregel/retry.py:120\u001b[0m, in \u001b[0;36marun_with_retry\u001b[0;34m(task, retry_policy, stream)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 120\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m task\u001b[38;5;241m.\u001b[39mproc\u001b[38;5;241m.\u001b[39mainvoke(task\u001b[38;5;241m.\u001b[39minput, task\u001b[38;5;241m.\u001b[39mconfig)\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# if successful, end\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/langchain_core/runnables/base.py:2541\u001b[0m, in \u001b[0;36mRunnableSequence.ainvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2537\u001b[0m config \u001b[38;5;241m=\u001b[39m patch_config(\n\u001b[1;32m   2538\u001b[0m     config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2539\u001b[0m )\n\u001b[1;32m   2540\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2541\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m step\u001b[38;5;241m.\u001b[39mainvoke(\u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   2542\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2543\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m step\u001b[38;5;241m.\u001b[39mainvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/langgraph/utils.py:121\u001b[0m, in \u001b[0;36mRunnableCallable.ainvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m         ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mcreate_task(\n\u001b[1;32m    118\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafunc(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), context\u001b[38;5;241m=\u001b[39mcontext\n\u001b[1;32m    119\u001b[0m         )\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 121\u001b[0m         ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafunc(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m ret\u001b[38;5;241m.\u001b[39mainvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[0;32mIn[13], line 29\u001b[0m, in \u001b[0;36mreplan_step\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m现在进行重新规划\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# print(state)\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m replanner\u001b[38;5;241m.\u001b[39mainvoke(state)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m现在输出重新规划结果\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(output)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/langchain_core/runnables/base.py:2543\u001b[0m, in \u001b[0;36mRunnableSequence.ainvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2541\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m step\u001b[38;5;241m.\u001b[39mainvoke(\u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   2542\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2543\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m step\u001b[38;5;241m.\u001b[39mainvoke(\u001b[38;5;28minput\u001b[39m, config)\n\u001b[1;32m   2544\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   2545\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/langchain_core/output_parsers/base.py:192\u001b[0m, in \u001b[0;36mBaseOutputParser.ainvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mainvoke\u001b[39m(\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28minput\u001b[39m: Union[\u001b[38;5;28mstr\u001b[39m, BaseMessage],\n\u001b[1;32m    188\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m    190\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28minput\u001b[39m, BaseMessage):\n\u001b[0;32m--> 192\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_acall_with_config(\n\u001b[1;32m    193\u001b[0m             \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maparse_result(\n\u001b[1;32m    194\u001b[0m                 [ChatGeneration(message\u001b[38;5;241m=\u001b[39minner_input)]\n\u001b[1;32m    195\u001b[0m             ),\n\u001b[1;32m    196\u001b[0m             \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    197\u001b[0m             config,\n\u001b[1;32m    198\u001b[0m             run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    199\u001b[0m         )\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    201\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_acall_with_config(\n\u001b[1;32m    202\u001b[0m             \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maparse_result([Generation(text\u001b[38;5;241m=\u001b[39minner_input)]),\n\u001b[1;32m    203\u001b[0m             \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    204\u001b[0m             config,\n\u001b[1;32m    205\u001b[0m             run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    206\u001b[0m         )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/langchain_core/runnables/base.py:1651\u001b[0m, in \u001b[0;36mRunnable._acall_with_config\u001b[0;34m(self, func, input, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1649\u001b[0m         output: Output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mcreate_task(coro, context\u001b[38;5;241m=\u001b[39mcontext)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   1650\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1651\u001b[0m         output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m coro\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/langchain_core/output_parsers/base.py:249\u001b[0m, in \u001b[0;36mBaseOutputParser.aparse_result\u001b[0;34m(self, result, partial)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maparse_result\u001b[39m(\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28mself\u001b[39m, result: List[Generation], \u001b[38;5;241m*\u001b[39m, partial: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    236\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    237\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Parse a list of candidate model Generations into a specific format.\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \n\u001b[1;32m    239\u001b[0m \u001b[38;5;124;03m    The return value is parsed from only the first Generation in the result, which\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;124;03m        Structured output.\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 249\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m run_in_executor(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_result, result, partial\u001b[38;5;241m=\u001b[39mpartial)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/langchain_core/runnables/config.py:557\u001b[0m, in \u001b[0;36mrun_in_executor\u001b[0;34m(executor_or_config, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[1;32m    555\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m executor_or_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(executor_or_config, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    556\u001b[0m     \u001b[38;5;66;03m# Use default executor with context copied from current context\u001b[39;00m\n\u001b[0;32m--> 557\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mget_running_loop()\u001b[38;5;241m.\u001b[39mrun_in_executor(\n\u001b[1;32m    558\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    559\u001b[0m         cast(Callable[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, T], partial(copy_context()\u001b[38;5;241m.\u001b[39mrun, wrapper)),\n\u001b[1;32m    560\u001b[0m     )\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mget_running_loop()\u001b[38;5;241m.\u001b[39mrun_in_executor(executor_or_config, wrapper)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/langchain_core/runnables/config.py:548\u001b[0m, in \u001b[0;36mrun_in_executor.<locals>.wrapper\u001b[0;34m()\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    547\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 548\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    550\u001b[0m         \u001b[38;5;66;03m# StopIteration can't be set on an asyncio.Future\u001b[39;00m\n\u001b[1;32m    551\u001b[0m         \u001b[38;5;66;03m# it raises a TypeError and leaves the Future pending forever\u001b[39;00m\n\u001b[1;32m    552\u001b[0m         \u001b[38;5;66;03m# so we need to convert it to a RuntimeError\u001b[39;00m\n\u001b[1;32m    553\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/langchain_core/output_parsers/pydantic.py:61\u001b[0m, in \u001b[0;36mPydanticOutputParser.parse_result\u001b[0;34m(self, result, partial)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_result\u001b[39m(\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28mself\u001b[39m, result: List[Generation], \u001b[38;5;241m*\u001b[39m, partial: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     59\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m TBaseModel:\n\u001b[1;32m     60\u001b[0m     json_object \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mparse_result(result)\n\u001b[0;32m---> 61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_obj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_object\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/langchain_core/output_parsers/pydantic.py:42\u001b[0m, in \u001b[0;36mPydanticOutputParser._parse_obj\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(\n\u001b[1;32m     38\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported model version for PydanticOutputParser: \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124m                    \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpydantic_object\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     40\u001b[0m             )\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (pydantic\u001b[38;5;241m.\u001b[39mValidationError, pydantic\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mValidationError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 42\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parser_exception(e, obj)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# pydantic v1\u001b[39;00m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mOutputParserException\u001b[0m: Failed to parse Act from completion {\"action\": \"Plan\", \"steps1\": \"Split the dataset into training and testing sets.\", \"steps2\": \"Create a Logistic Regression model and train it on the training set.\", \"steps3\": \"Evaluate the model on the testing set and output the performance metrics.\"}. Got: 2 validation errors for Act\naction\n  value is not a valid dict (type=type_error.dict)\naction\n  value is not a valid dict (type=type_error.dict)"
     ]
    }
   ],
   "source": [
    "config = {\"recursion_limit\": 15}\n",
    "inputs = {\"input\": \"Task decomposition and Load the iris dataset and write the code for sklearn machine learning regression?\"}\n",
    "async for event in app.astream(inputs, config=config):\n",
    "    for k, v in event.items():\n",
    "        if k != \"__end__\":\n",
    "            print('————————————————————————————————————————————————当前的K')\n",
    "            print(k)\n",
    "            print('————————————————————————————————————————————————当前的V')\n",
    "            print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06327fdf-fb15-4f0f-a71e-88effce2abe7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T10:50:51.545573Z",
     "iopub.status.busy": "2024-07-10T10:50:51.545190Z",
     "iopub.status.idle": "2024-07-10T10:50:51.550074Z",
     "shell.execute_reply": "2024-07-10T10:50:51.549237Z",
     "shell.execute_reply.started": "2024-07-10T10:50:51.545552Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'past_steps': ['Split the dataset into training and testing sets.',\n",
       "  \"To execute step 1, you would typically use a programming language like Python and a library such as scikit-learn, which provides a convenient function to split datasets. However, since I can't execute code, I'll guide you through the process conceptually.\\n\\nHere's how you would generally split a dataset into training and testing sets using scikit-learn:\\n\\n```python\\nfrom sklearn.model_selection import train_test_split\\n\\n# Assuming 'data' is your dataset and 'labels' are the corresponding labels\\n\\n# Define the size of the testing set (commonly 20% or 30% of the whole dataset)\\ntest_size = 0.2\\n\\n# Split the data into training and testing sets\\nX_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=test_size, random_state=42)\\n\\n# 'X_train' and 'y_train' are the training data and labels\\n# 'X_test' and 'y_test' are the testing data and labels\\n```\\n\\nThe `train_test_split` function takes the following important parameters:\\n\\n- `data`: Your feature dataset, which you want to split.\\n- `labels`: The corresponding labels for your data.\\n- `test_size`: The proportion of the dataset to include in the test split (can be a float or an integer for the number of test samples).\\n- `random_state`: Optional, controls the shuffling applied to the data before applying the split. It's useful for creating reproducible splits.\\n\\nPlease note that this is just a conceptual explanation. To actually perform the split, you would need to write and run this code in a Python environment with the necessary libraries installed.\"]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
