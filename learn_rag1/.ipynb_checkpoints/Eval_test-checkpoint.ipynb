{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9195d6ca-35db-4034-a96e-98c940be6f56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T10:05:44.649087Z",
     "iopub.status.busy": "2024-07-03T10:05:44.648892Z",
     "iopub.status.idle": "2024-07-03T10:05:46.565716Z",
     "shell.execute_reply": "2024-07-03T10:05:46.565157Z",
     "shell.execute_reply.started": "2024-07-03T10:05:44.649071Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "documents = []\n",
    "dc_name = [\"soybean_konw.pdf\", \"soybean2.pdf\"]\n",
    "for tmp_name in dc_name:\n",
    "    # print(len(PyPDFLoader(tmp_name).load()))\n",
    "    documents += PyPDFLoader(tmp_name).load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=200)\n",
    "texts = text_splitter.split_documents(documents[:])\n",
    "for idx, text in enumerate(texts):\n",
    "    text.metadata[\"id\"] = idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d678d1ff-0def-4703-a866-18a0201ff37c",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-04T07:16:12.490129Z",
     "iopub.status.busy": "2024-07-04T07:16:12.489816Z",
     "iopub.status.idle": "2024-07-04T07:16:21.983905Z",
     "shell.execute_reply": "2024-07-04T07:16:21.983356Z",
     "shell.execute_reply.started": "2024-07-04T07:16:12.490110Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain.schema import Document\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n",
    "top_k = 10\n",
    "\n",
    "model_name = '/mnt/workspace/.cache/modelscope/hub/maple77/zpoint_large_embedding_zh'\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': True}\n",
    "hf = HuggingFaceBgeEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")\n",
    "vectorstore = Chroma(persist_directory=\"soybean_db2\", embedding_function=hf)\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": top_k}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76a4d1c5-a530-4119-ae47-d190313c47b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T07:16:21.985352Z",
     "iopub.status.busy": "2024-07-04T07:16:21.984958Z",
     "iopub.status.idle": "2024-07-04T07:16:22.308294Z",
     "shell.execute_reply": "2024-07-04T07:16:22.307736Z",
     "shell.execute_reply.started": "2024-07-04T07:16:21.985332Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['id', 'source', 'page', 'question', 'ground_truth', 'context'])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('soybean_q_gt_609.xlsx', sheet_name='Sheet1')\n",
    "\n",
    "# 打印DataFrame的内容\n",
    "column_lists = {col: df[col].tolist() for col in df.columns}\n",
    "print(column_lists.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09907594-154a-485a-af18-3c195df11149",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-04T07:16:23.822099Z",
     "iopub.status.busy": "2024-07-04T07:16:23.821555Z",
     "iopub.status.idle": "2024-07-04T07:17:04.100518Z",
     "shell.execute_reply": "2024-07-04T07:17:04.099928Z",
     "shell.execute_reply.started": "2024-07-04T07:16:23.822076Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Get retriever result: 100%|██████████| 10/10 [00:40<00:00,  4.03s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm, trange\n",
    "\n",
    "s_index = 10\n",
    "\n",
    "retriever_result = []\n",
    "for tmp_q in tqdm(range(len(column_lists['question'][:s_index])), desc='Get retriever result'):\n",
    "    # print(tmp_q)\n",
    "    retriever_result.append(retriever.invoke(column_lists['question'][tmp_q]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27f6968-86c5-4003-90b2-4fc4bed3a212",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# retriever_result = retriever.batch(column_lists['question'][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa34ed9a-c34c-4e5e-9189-079b55a60dcb",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-04T07:17:04.101760Z",
     "iopub.status.busy": "2024-07-04T07:17:04.101497Z",
     "iopub.status.idle": "2024-07-04T07:17:04.108953Z",
     "shell.execute_reply": "2024-07-04T07:17:04.108418Z",
     "shell.execute_reply.started": "2024-07-04T07:17:04.101743Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'top_3': {'ht_score': 0.1,\n",
       "  'mmr_score': 0.1,\n",
       "  'soft_ht_score': 0.3,\n",
       "  'soft_mmr_score': 0.233,\n",
       "  'ndcg': 0.25},\n",
       " 'top_4': {'ht_score': 0.1,\n",
       "  'mmr_score': 0.1,\n",
       "  'soft_ht_score': 0.4,\n",
       "  'soft_mmr_score': 0.258,\n",
       "  'ndcg': 0.293},\n",
       " 'top_5': {'ht_score': 0.1,\n",
       "  'mmr_score': 0.1,\n",
       "  'soft_ht_score': 0.4,\n",
       "  'soft_mmr_score': 0.278,\n",
       "  'ndcg': 0.293},\n",
       " 'top_6': {'ht_score': 0.1,\n",
       "  'mmr_score': 0.1,\n",
       "  'soft_ht_score': 0.5,\n",
       "  'soft_mmr_score': 0.295,\n",
       "  'ndcg': 0.329},\n",
       " 'top_7': {'ht_score': 0.2,\n",
       "  'mmr_score': 0.114,\n",
       "  'soft_ht_score': 0.5,\n",
       "  'soft_mmr_score': 0.324,\n",
       "  'ndcg': 0.328},\n",
       " 'top_8': {'ht_score': 0.3,\n",
       "  'mmr_score': 0.127,\n",
       "  'soft_ht_score': 0.6,\n",
       "  'soft_mmr_score': 0.349,\n",
       "  'ndcg': 0.35},\n",
       " 'top_9': {'ht_score': 0.3,\n",
       "  'mmr_score': 0.127,\n",
       "  'soft_ht_score': 0.6,\n",
       "  'soft_mmr_score': 0.36,\n",
       "  'ndcg': 0.353},\n",
       " 'top_10': {'ht_score': 0.3,\n",
       "  'mmr_score': 0.127,\n",
       "  'soft_ht_score': 0.6,\n",
       "  'soft_mmr_score': 0.36,\n",
       "  'ndcg': 0.353}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from retiever_eval_list import get_result_retrieva\n",
    "col_id = column_lists['id'][:s_index]\n",
    "retriever_re = get_result_retrieva(col_id, retriever_result)\n",
    "retriever_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d67c3c17-2255-4ede-b355-0e983361b805",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T07:17:04.109963Z",
     "iopub.status.busy": "2024-07-04T07:17:04.109626Z",
     "iopub.status.idle": "2024-07-04T07:17:06.731146Z",
     "shell.execute_reply": "2024-07-04T07:17:06.730466Z",
     "shell.execute_reply.started": "2024-07-04T07:17:04.109944Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('/mnt/workspace/.cache/modelscope/hub/Xorbits/bge-reranker-base')\n",
    "rerank_model = AutoModelForSequenceClassification.from_pretrained('/mnt/workspace/.cache/modelscope/hub/Xorbits/bge-reranker-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c07c6783-4646-4b75-8ce3-12f0b38d7bcf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T07:17:06.733142Z",
     "iopub.status.busy": "2024-07-04T07:17:06.732810Z",
     "iopub.status.idle": "2024-07-04T07:18:01.098693Z",
     "shell.execute_reply": "2024-07-04T07:18:01.097863Z",
     "shell.execute_reply.started": "2024-07-04T07:17:06.733117Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rerank result: 100%|██████████| 10/10 [00:54<00:00,  5.44s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "question_rerank_result = []\n",
    "for query_idx in trange(len(column_lists['question'][:s_index]), desc='Rerank result'):\n",
    "    pairs = []\n",
    "    for idx in range(len(retriever_result[query_idx])):\n",
    "        pairs.append([column_lists['question'][:s_index][query_idx], retriever_result[query_idx][idx].page_content])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer(pairs, padding=True, truncation=True, return_tensors='pt', max_length=512)\n",
    "        scores = rerank_model(**inputs, return_dict=True).logits.view(-1, ).float()\n",
    "    combined = sorted(zip(scores, retriever_result[query_idx]), reverse=True)\n",
    "    scores_rerank_list, retri_rerank_list = zip(*combined)\n",
    "    # print(scores_rerank_list, retri_rerank_list)\n",
    "    question_rerank_result.append(retri_rerank_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2ef376c-f24e-474f-be86-657b2d1848f4",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-04T07:18:01.099766Z",
     "iopub.status.busy": "2024-07-04T07:18:01.099494Z",
     "iopub.status.idle": "2024-07-04T07:18:01.104707Z",
     "shell.execute_reply": "2024-07-04T07:18:01.104244Z",
     "shell.execute_reply.started": "2024-07-04T07:18:01.099749Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'top_3': {'ht_score': 0.2,\n",
       "  'mmr_score': 0.1,\n",
       "  'soft_ht_score': 0.5,\n",
       "  'soft_mmr_score': 0.5,\n",
       "  'ndcg': 0.443},\n",
       " 'top_4': {'ht_score': 0.2,\n",
       "  'mmr_score': 0.1,\n",
       "  'soft_ht_score': 0.5,\n",
       "  'soft_mmr_score': 0.5,\n",
       "  'ndcg': 0.443},\n",
       " 'top_5': {'ht_score': 0.2,\n",
       "  'mmr_score': 0.1,\n",
       "  'soft_ht_score': 0.5,\n",
       "  'soft_mmr_score': 0.5,\n",
       "  'ndcg': 0.443},\n",
       " 'top_6': {'ht_score': 0.2,\n",
       "  'mmr_score': 0.1,\n",
       "  'soft_ht_score': 0.5,\n",
       "  'soft_mmr_score': 0.5,\n",
       "  'ndcg': 0.443},\n",
       " 'top_7': {'ht_score': 0.2,\n",
       "  'mmr_score': 0.1,\n",
       "  'soft_ht_score': 0.5,\n",
       "  'soft_mmr_score': 0.5,\n",
       "  'ndcg': 0.443},\n",
       " 'top_8': {'ht_score': 0.3,\n",
       "  'mmr_score': 0.113,\n",
       "  'soft_ht_score': 0.6,\n",
       "  'soft_mmr_score': 0.525,\n",
       "  'ndcg': 0.462},\n",
       " 'top_9': {'ht_score': 0.3,\n",
       "  'mmr_score': 0.113,\n",
       "  'soft_ht_score': 0.6,\n",
       "  'soft_mmr_score': 0.536,\n",
       "  'ndcg': 0.467},\n",
       " 'top_10': {'ht_score': 0.3,\n",
       "  'mmr_score': 0.113,\n",
       "  'soft_ht_score': 0.6,\n",
       "  'soft_mmr_score': 0.556,\n",
       "  'ndcg': 0.464}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_id = column_lists['id'][:s_index]\n",
    "rerank_result = get_result_retrieva(col_id, question_rerank_result)\n",
    "rerank_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c54e375-ec7d-4f95-b327-ec3c00a7d4d6",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-04T07:18:15.673519Z",
     "iopub.status.busy": "2024-07-04T07:18:15.673120Z",
     "iopub.status.idle": "2024-07-04T07:18:15.677598Z",
     "shell.execute_reply": "2024-07-04T07:18:15.677079Z",
     "shell.execute_reply.started": "2024-07-04T07:18:15.673499Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10, 10, 10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(question_rerank_result), len(question_rerank_result[0]), len(column_lists['question'][:s_index]), len(column_lists['ground_truth'][:s_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03911864-9e4a-4804-bff6-8da16cfd65d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T07:18:16.753976Z",
     "iopub.status.busy": "2024-07-04T07:18:16.753635Z",
     "iopub.status.idle": "2024-07-04T07:18:16.846084Z",
     "shell.execute_reply": "2024-07-04T07:18:16.845520Z",
     "shell.execute_reply.started": "2024-07-04T07:18:16.753957Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.schema import Document\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_relevancy,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.6,\n",
    "    model=\"glm-4-0520\",\n",
    "    openai_api_key=\"661a7aa0aeb8ca129eb4647461123230.bl9w581QKpnMfBvs\",\n",
    "    openai_api_base=\"https://open.bigmodel.cn/api/paas/v4/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65b9d2eb-3956-4ce7-935c-443d91160e5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T07:18:18.454076Z",
     "iopub.status.busy": "2024-07-04T07:18:18.453728Z",
     "iopub.status.idle": "2024-07-04T07:18:18.457807Z",
     "shell.execute_reply": "2024-07-04T07:18:18.457230Z",
     "shell.execute_reply.started": "2024-07-04T07:18:18.454056Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['context', 'question'] template=\"You are an assistant for question-answering tasks. \\nUse the following pieces of retrieved context to answer the question. \\nIf you don't know the answer, just say that you don't know. \\n\\nQuestion: {question} \\n\\nContext: {context} \\n\\nAnswer:\\n\"\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "template = \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "\n",
    "Question: {question} \n",
    "\n",
    "Context: {context} \n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template, \n",
    "    input_variables=[\"context\",\"question\"]\n",
    "  )\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72338ca6-f679-4490-8c46-d9b5475caf38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T07:18:20.236507Z",
     "iopub.status.busy": "2024-07-04T07:18:20.236141Z",
     "iopub.status.idle": "2024-07-04T07:18:20.240353Z",
     "shell.execute_reply": "2024-07-04T07:18:20.239808Z",
     "shell.execute_reply.started": "2024-07-04T07:18:20.236487Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "rag_chain = (\n",
    "    {\"context\": RunnablePassthrough(),  \"question\": RunnablePassthrough()} \n",
    "    | prompt \n",
    "    | llm\n",
    "    | StrOutputParser() \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70e75a28-5228-40dc-ab1c-d15ff12a2f26",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-04T07:18:22.485354Z",
     "iopub.status.busy": "2024-07-04T07:18:22.484997Z",
     "iopub.status.idle": "2024-07-04T07:19:24.949110Z",
     "shell.execute_reply": "2024-07-04T07:19:24.948534Z",
     "shell.execute_reply.started": "2024-07-04T07:18:22.485335Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Get answer: 100%|██████████| 10/10 [01:02<00:00,  6.25s/it]\n"
     ]
    }
   ],
   "source": [
    "answers = []\n",
    "context_list = []\n",
    "for i in trange(len(column_lists['question'][:s_index]), desc='Get answer'):\n",
    "    query_tmp = column_lists['question'][i]\n",
    "    context_tmp = ''.join(qr.page_content for qr in question_rerank_result[i])\n",
    "    inputs = {\"context\": context_tmp, \"question\": query_tmp}\n",
    "    answers.append(rag_chain.invoke(inputs))\n",
    "    context_list.append([docs.page_content for docs in question_rerank_result[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae1ebf10-5382-43f1-af1e-537a7437cb82",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-04T07:19:24.954098Z",
     "iopub.status.busy": "2024-07-04T07:19:24.953830Z",
     "iopub.status.idle": "2024-07-04T07:19:24.968222Z",
     "shell.execute_reply": "2024-07-04T07:19:24.967698Z",
     "shell.execute_reply.started": "2024-07-04T07:19:24.954080Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer', 'contexts', 'ground_truth'],\n",
       "    num_rows: 10\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from langchain_community.chat_models import ChatZhipuAI\n",
    "import os\n",
    "# 构建数据\n",
    "data = {\n",
    "    \"question\": column_lists['question'][:s_index],\n",
    "    \"answer\": answers,\n",
    "    \"contexts\": context_list,\n",
    "    \"ground_truth\": column_lists['ground_truth'][:s_index]\n",
    "}\n",
    "dataset = Dataset.from_dict(data)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8bf58c0-75f9-48c6-8aa8-97d357a2e2a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T07:31:34.080435Z",
     "iopub.status.busy": "2024-07-04T07:31:34.080077Z",
     "iopub.status.idle": "2024-07-04T07:31:34.084478Z",
     "shell.execute_reply": "2024-07-04T07:31:34.083932Z",
     "shell.execute_reply.started": "2024-07-04T07:31:34.080414Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "# 指定你想要保存的文件名\n",
    "filename = \"my_data.json\"\n",
    "\n",
    "# 使用json.dump()将字典保存为json文件\n",
    "with open(filename, 'w', encoding='utf-8') as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49f94cd-b4e6-401d-9da2-9f0bf662f3cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 指定之前保存的文件名\n",
    "filename = \"my_data.json\"\n",
    "\n",
    "# 使用json.load()从json文件加载数据到字典\n",
    "with open(filename, 'r', encoding='utf-8') as f:\n",
    "    loaded_dict = json.load(f)\n",
    "\n",
    "print(loaded_dict)  # 输出加载的字典内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64019072-8abf-4e9b-beac-813427020508",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-04T07:19:28.529136Z",
     "iopub.status.busy": "2024-07-04T07:19:28.528778Z",
     "iopub.status.idle": "2024-07-04T07:19:28.532812Z",
     "shell.execute_reply": "2024-07-04T07:19:28.532185Z",
     "shell.execute_reply.started": "2024-07-04T07:19:28.529116Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade httpx httpx-sse PyJWT\n",
    "os.environ[\"ZHIPUAI_API_KEY\"] = \"661a7aa0aeb8ca129eb4647461123230.bl9w581QKpnMfBvs\"\n",
    "chat = ChatZhipuAI(\n",
    "    model=\"glm-4-0520\",\n",
    "    temperature=0.5,\n",
    ")\n",
    "metrics = [\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_recall,\n",
    "    context_precision\n",
    "]\n",
    "langchain_embeddings = LangchainEmbeddingsWrapper(hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ecf62c7-0627-4ba7-8ae2-87cf552a6bfe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T07:28:17.545936Z",
     "iopub.status.busy": "2024-07-04T07:28:17.545598Z",
     "iopub.status.idle": "2024-07-04T07:28:17.549445Z",
     "shell.execute_reply": "2024-07-04T07:28:17.548869Z",
     "shell.execute_reply.started": "2024-07-04T07:28:17.545918Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer', 'contexts', 'ground_truth'],\n",
       "    num_rows: 10\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "db046458-0aed-4fb3-afc0-31eb4153b093",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-04T07:28:04.288006Z",
     "iopub.status.busy": "2024-07-04T07:28:04.287635Z",
     "iopub.status.idle": "2024-07-04T07:28:04.348512Z",
     "shell.execute_reply": "2024-07-04T07:28:04.347855Z",
     "shell.execute_reply.started": "2024-07-04T07:28:04.287985Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-11:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.10/site-packages/ragas/executor.py\", line 87, in run\n",
      "    results = self.loop.run_until_complete(self._aresults())\n",
      "  File \"/usr/local/lib/python3.10/asyncio/base_events.py\", line 625, in run_until_complete\n",
      "    self._check_running()\n",
      "  File \"/usr/local/lib/python3.10/asyncio/base_events.py\", line 584, in _check_running\n",
      "    raise RuntimeError('This event loop is already running')\n",
      "RuntimeError: This event loop is already running\n",
      "/usr/local/lib/python3.10/threading.py:1018: RuntimeWarning: coroutine 'Runner._aresults' was never awaited\n",
      "  self._invoke_excepthook(self)\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/usr/local/lib/python3.10/genericpath.py:77: RuntimeWarning: coroutine 'Executor.wrap_callable_with_index.<locals>.wrapped_callable_async' was never awaited\n",
      "  m = tuple(map(os.fspath, m))\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "ename": "ExceptionInRunner",
     "evalue": "The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mExceptionInRunner\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlangchain_embeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m results\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/ragas/evaluation.py:255\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(dataset, metrics, llm, embeddings, callbacks, in_ci, is_async, run_config, raise_exceptions, column_map)\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evaluation_group_cm\u001b[38;5;241m.\u001b[39mended:\n\u001b[1;32m    253\u001b[0m         evaluation_rm\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 255\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     result \u001b[38;5;241m=\u001b[39m Result(\n\u001b[1;32m    258\u001b[0m         scores\u001b[38;5;241m=\u001b[39mDataset\u001b[38;5;241m.\u001b[39mfrom_list(scores),\n\u001b[1;32m    259\u001b[0m         dataset\u001b[38;5;241m=\u001b[39mdataset,\n\u001b[1;32m    260\u001b[0m         binary_columns\u001b[38;5;241m=\u001b[39mbinary_metrics,\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/ragas/evaluation.py:237\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(dataset, metrics, llm, embeddings, callbacks, in_ci, is_async, run_config, raise_exceptions, column_map)\u001b[0m\n\u001b[1;32m    235\u001b[0m results \u001b[38;5;241m=\u001b[39m executor\u001b[38;5;241m.\u001b[39mresults()\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m results \u001b[38;5;241m==\u001b[39m []:\n\u001b[0;32m--> 237\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ExceptionInRunner()\n\u001b[1;32m    239\u001b[0m \u001b[38;5;66;03m# convert results to dataset_like\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataset):\n",
      "\u001b[0;31mExceptionInRunner\u001b[0m: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/ipykernel/iostream.py:123: RuntimeWarning: coroutine 'as_completed.<locals>.sema_coro' was never awaited\n",
      "  await self._event_pipe_gc()\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "results = evaluate(dataset = dataset, metrics=metrics, llm=chat, embeddings=langchain_embeddings)\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
