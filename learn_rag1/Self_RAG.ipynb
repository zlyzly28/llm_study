{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9aa8e0-72d7-4c1b-83e6-6d4770793d6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "844a2cba-32f4-4ad6-b6ef-bab2246a27e9",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-11T07:46:21.981004Z",
     "iopub.status.busy": "2024-07-11T07:46:21.980609Z",
     "iopub.status.idle": "2024-07-11T07:46:34.378767Z",
     "shell.execute_reply": "2024-07-11T07:46:34.378032Z",
     "shell.execute_reply.started": "2024-07-11T07:46:21.980978Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "documents = []\n",
    "dc_name = [\"soybean_konw.pdf\", \"soybean2.pdf\"]\n",
    "for tmp_name in dc_name:\n",
    "    # print(len(PyPDFLoader(tmp_name).load()))\n",
    "    documents += PyPDFLoader(tmp_name).load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=200)\n",
    "texts = text_splitter.split_documents(documents[:])\n",
    "for idx, text in enumerate(texts):\n",
    "    text.metadata[\"id\"] = idx\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.schema import Document\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n",
    "top_k = 10\n",
    "\n",
    "model_name = '/mnt/workspace/.cache/modelscope/hub/maple77/zpoint_large_embedding_zh'\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': True}\n",
    "hf = HuggingFaceBgeEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")\n",
    "vectorstore = Chroma(persist_directory=\"soybean_db2\", embedding_function=hf)\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": top_k}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e851a431-7fb0-434f-90c5-016fd5a5cb93",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-11T07:45:49.938374Z",
     "iopub.status.busy": "2024-07-11T07:45:49.937872Z",
     "iopub.status.idle": "2024-07-11T07:45:50.194923Z",
     "shell.execute_reply": "2024-07-11T07:45:50.194228Z",
     "shell.execute_reply.started": "2024-07-11T07:45:49.938339Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing import List\n",
    "from typing import Literal, Optional, Tuple\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "# Data model\n",
    "class GradeDocuments(BaseModel):\n",
    "    \"\"\"Binary score for relevance check on retrieved documents.\"\"\"\n",
    "\n",
    "    binary_score: Literal[\"yes\", \"no\"] = Field(\n",
    "        ...,\n",
    "        description=\"Documents are relevant to the question, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "# LLM with function call\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.6,\n",
    "    model=\"glm-4-0520\",\n",
    "    openai_api_key=\"661a7aa0aeb8ca129eb4647461123230.bl9w581QKpnMfBvs\",\n",
    "    openai_api_base=\"https://open.bigmodel.cn/api/paas/v4/\"\n",
    ")\n",
    "# structured_llm_grader = llm.with_structured_output(GradeDocuments)\n",
    "# Set up a parser\n",
    "parser = PydanticOutputParser(pydantic_object=GradeDocuments)\n",
    "# Prompt\n",
    "system = \"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n \n",
    "    If the document contains keyword(s) or semantic meaning related to the question, grade it as relevant. \\n\n",
    "    Answer the user query. Wrap the output in `json` tags\\n{format_instructions}\"\"\"\n",
    "grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Retrieved document: \\n\\n {document} \\n\\n User question: {question}\"),\n",
    "    ]\n",
    ").partial(format_instructions=parser.get_format_instructions())\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.7,\n",
    "    model=\"glm-4-0520\",\n",
    "    openai_api_key=\"661a7aa0aeb8ca129eb4647461123230.bl9w581QKpnMfBvs\",\n",
    "    openai_api_base=\"https://open.bigmodel.cn/api/paas/v4/\"\n",
    ")\n",
    "\n",
    "retrieval_grader = grade_prompt | llm | parser\n",
    "# question = \"agent memory\"\n",
    "# docs = retriever.invoke(question)\n",
    "# doc_txt = texts[3].page_content\n",
    "# print(retrieval_grader.invoke({\"question\": question, \"document\": doc_txt}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "131ec65e-c097-4d78-9b28-9e89476d55a5",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-11T07:45:52.866858Z",
     "iopub.status.busy": "2024-07-11T07:45:52.866468Z",
     "iopub.status.idle": "2024-07-11T07:45:52.965729Z",
     "shell.execute_reply": "2024-07-11T07:45:52.965050Z",
     "shell.execute_reply.started": "2024-07-11T07:45:52.866832Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Generate\n",
    "from langchain import PromptTemplate\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "# Prompt\n",
    "# prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "template = \"\"\"\n",
    "You are an expert in phenomics in agronomy, and you have a very rich knowledge of agronomy and phenomics.\n",
    "Use the context snippets retrieved below to answer the agronomy question from a phenotypic point of view.\n",
    "If if you don't know the answer, say you don't know.\n",
    "\n",
    "Question: {question} \n",
    "\n",
    "Context: {context} \n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template, \n",
    "    input_variables=[\"context\",\"question\"]\n",
    "  )\n",
    "# LLM\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.6,\n",
    "    model=\"glm-4-0520\",\n",
    "    openai_api_key=\"661a7aa0aeb8ca129eb4647461123230.bl9w581QKpnMfBvs\",\n",
    "    openai_api_base=\"https://open.bigmodel.cn/api/paas/v4/\"\n",
    ")\n",
    "\n",
    "\n",
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Chain\n",
    "# rag_chain = prompt | llm | StrOutputParser()\n",
    "rag_chain = (\n",
    "    {\"context\": RunnablePassthrough(),  \"question\": RunnablePassthrough()} \n",
    "    | prompt \n",
    "    | llm\n",
    "    | StrOutputParser() \n",
    ")\n",
    "# Run\n",
    "# generation = rag_chain.invoke({\"context\": docs, \"question\": question})\n",
    "# print(generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30cc0c23-7417-44bb-9cf0-4c3149f2ace0",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-11T07:45:55.105372Z",
     "iopub.status.busy": "2024-07-11T07:45:55.104999Z",
     "iopub.status.idle": "2024-07-11T07:45:55.204368Z",
     "shell.execute_reply": "2024-07-11T07:45:55.203648Z",
     "shell.execute_reply.started": "2024-07-11T07:45:55.105352Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Hallucination Grader\n",
    "from typing import List\n",
    "from typing import Literal, Optional, Tuple\n",
    "\n",
    "# Data model\n",
    "class GradeHallucinations(BaseModel):\n",
    "    \"\"\"Binary score for hallucination present in generation answer.\"\"\"\n",
    "\n",
    "    binary_score: Literal[\"yes\", \"no\"] = Field(\n",
    "        ...,\n",
    "        description=\"Answer is grounded in the facts, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "parser2 = PydanticOutputParser(pydantic_object=GradeHallucinations)\n",
    "# LLM with function call\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.6,\n",
    "    model=\"glm-4-0520\",\n",
    "    openai_api_key=\"661a7aa0aeb8ca129eb4647461123230.bl9w581QKpnMfBvs\",\n",
    "    openai_api_base=\"https://open.bigmodel.cn/api/paas/v4/\"\n",
    ")\n",
    "# structured_llm_grader = llm.with_structured_output(GradeHallucinations)\n",
    "\n",
    "# Prompt\n",
    "system = \"\"\"You are a grader assessing whether an LLM generation is grounded in / supported by a set of retrieved facts. \\n \n",
    "     Give a binary score 'yes' or 'no'. 'Yes' means that the answer is grounded in / supported by the set of facts.\n",
    "     Answer the user query. Wrap the output in `json` tags\\n{format_instructions}\"\"\"\n",
    "hallucination_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Set of facts: \\n\\n {documents} \\n\\n LLM generation: {generation}\"),\n",
    "    ]\n",
    ").partial(format_instructions=parser.get_format_instructions())\n",
    "\n",
    "hallucination_grader = hallucination_prompt | llm | parser2\n",
    "# hallucination_grader.invoke({\"documents\": docs, \"generation\": generation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82f61967-9e51-4dac-960a-44f562c64458",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-11T07:45:58.648882Z",
     "iopub.status.busy": "2024-07-11T07:45:58.648500Z",
     "iopub.status.idle": "2024-07-11T07:45:58.743314Z",
     "shell.execute_reply": "2024-07-11T07:45:58.742653Z",
     "shell.execute_reply.started": "2024-07-11T07:45:58.648861Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data model\n",
    "class GradeAnswer(BaseModel):\n",
    "    \"\"\"Binary score to assess answer addresses question.\"\"\"\n",
    "\n",
    "    binary_score: Literal[\"yes\", \"no\"] = Field(\n",
    "        ...,\n",
    "        description=\"Answer addresses the question, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "parser3 = PydanticOutputParser(pydantic_object=GradeHallucinations)\n",
    "# LLM with function call\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.6,\n",
    "    model=\"glm-4-0520\",\n",
    "    openai_api_key=\"661a7aa0aeb8ca129eb4647461123230.bl9w581QKpnMfBvs\",\n",
    "    openai_api_base=\"https://open.bigmodel.cn/api/paas/v4/\"\n",
    ")\n",
    "\n",
    "# Prompt\n",
    "system = \"\"\"You are a grader assessing whether an answer addresses / resolves a question \\n \n",
    "     Give a binary score 'yes' or 'no'. Yes' means that the answer resolves the question.\\n\n",
    "     Answer the user query. Wrap the output in `json` tags\\n{format_instructions}\"\"\"\n",
    "answer_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"User question: \\n\\n {question} \\n\\n LLM generation: {generation}\"),\n",
    "    ]\n",
    ").partial(format_instructions=parser.get_format_instructions())\n",
    "\n",
    "answer_grader = answer_prompt | llm | parser3\n",
    "# answer_grader.invoke({\"question\": question, \"generation\": generation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bea57f31-1f7b-464c-a6a7-995fd471fffa",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-11T07:46:00.623726Z",
     "iopub.status.busy": "2024-07-11T07:46:00.623349Z",
     "iopub.status.idle": "2024-07-11T07:46:00.716917Z",
     "shell.execute_reply": "2024-07-11T07:46:00.716164Z",
     "shell.execute_reply.started": "2024-07-11T07:46:00.623706Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Question Re-writer\n",
    "\n",
    "# LLM\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.6,\n",
    "    model=\"glm-4-0520\",\n",
    "    openai_api_key=\"661a7aa0aeb8ca129eb4647461123230.bl9w581QKpnMfBvs\",\n",
    "    openai_api_base=\"https://open.bigmodel.cn/api/paas/v4/\"\n",
    ")\n",
    "\n",
    "# Prompt\n",
    "system = \"\"\"You a question re-writer that converts an input question to a better version that is optimized \\n \n",
    "     for vectorstore retrieval. Look at the input and try to reason about the underlying semantic intent / meaning.\"\"\"\n",
    "re_write_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Here is the initial question: \\n\\n {question} \\n Formulate an improved question.\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_rewriter = re_write_prompt | llm | StrOutputParser()\n",
    "# question_rewriter.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3da7eca-b53b-4c61-8787-290672a50bf7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-11T07:46:02.391708Z",
     "iopub.status.busy": "2024-07-11T07:46:02.391339Z",
     "iopub.status.idle": "2024-07-11T07:46:02.395286Z",
     "shell.execute_reply": "2024-07-11T07:46:02.394656Z",
     "shell.execute_reply.started": "2024-07-11T07:46:02.391687Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        question: question\n",
    "        generation: LLM generation\n",
    "        documents: list of documents\n",
    "    \"\"\"\n",
    "\n",
    "    question: str\n",
    "    generation: str\n",
    "    documents: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "babec9f0-99db-4a3e-a7e5-63961a97ebc8",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-11T07:46:03.713055Z",
     "iopub.status.busy": "2024-07-11T07:46:03.712667Z",
     "iopub.status.idle": "2024-07-11T07:46:03.716688Z",
     "shell.execute_reply": "2024-07-11T07:46:03.716037Z",
     "shell.execute_reply.started": "2024-07-11T07:46:03.713033Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Nodes\n",
    "\n",
    "\n",
    "def retrieve(state):\n",
    "    \"\"\"\n",
    "    Retrieve documents\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, documents, that contains retrieved documents\n",
    "    \"\"\"\n",
    "    print(\"---检索文档中---\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # Retrieval\n",
    "    documents = retriever.invoke(question)\n",
    "    return {\"documents\": documents, \"question\": question}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2bb2f3f-41ef-49dd-8855-caeb6e29a663",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-11T07:46:05.006105Z",
     "iopub.status.busy": "2024-07-11T07:46:05.005722Z",
     "iopub.status.idle": "2024-07-11T07:46:05.010409Z",
     "shell.execute_reply": "2024-07-11T07:46:05.009668Z",
     "shell.execute_reply.started": "2024-07-11T07:46:05.006083Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate(state):\n",
    "    \"\"\"\n",
    "    Generate answer\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation, that contains LLM generation\n",
    "    \"\"\"\n",
    "    print(\"---正在根据检索结果 生成回答---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    dok_tmp = '\\n\\n'.join([dk.page_content for dk in documents])\n",
    "\n",
    "    # RAG generation\n",
    "    generation = rag_chain.invoke({\"context\": dok_tmp, \"question\": question})\n",
    "    return {\"documents\": documents, \"question\": question, \"generation\": generation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a222537-bfc9-46b3-af18-b0dd746cb9bc",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-11T07:46:06.521485Z",
     "iopub.status.busy": "2024-07-11T07:46:06.521122Z",
     "iopub.status.idle": "2024-07-11T07:46:06.526275Z",
     "shell.execute_reply": "2024-07-11T07:46:06.525594Z",
     "shell.execute_reply.started": "2024-07-11T07:46:06.521464Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def grade_documents(state):\n",
    "    \"\"\"\n",
    "    Determines whether the retrieved documents are relevant to the question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Updates documents key with only filtered relevant documents\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---检查该问题是否与检索文档相关---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # Score each doc\n",
    "    filtered_docs = []\n",
    "    for d in documents:\n",
    "        score = retrieval_grader.invoke(\n",
    "            {\"question\": question, \"document\": d.page_content}\n",
    "        )\n",
    "        grade = score.binary_score\n",
    "        if grade == \"yes\":\n",
    "            print(\"---GRADE: 该文档与结果相关---\")\n",
    "            filtered_docs.append(d)\n",
    "        else:\n",
    "            print(\"---GRADE: 该文档与结果不相关---\")\n",
    "            continue\n",
    "    return {\"documents\": filtered_docs, \"question\": question}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15d54f9c-6c90-47ad-965a-f58429ea80f5",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-11T07:46:08.254885Z",
     "iopub.status.busy": "2024-07-11T07:46:08.254513Z",
     "iopub.status.idle": "2024-07-11T07:46:08.258511Z",
     "shell.execute_reply": "2024-07-11T07:46:08.257919Z",
     "shell.execute_reply.started": "2024-07-11T07:46:08.254865Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def transform_query(state):\n",
    "    \"\"\"\n",
    "    Transform the query to produce a better question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Updates question key with a re-phrased question\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---将问题进行重写一个新的问题---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # Re-write question\n",
    "    better_question = question_rewriter.invoke({\"question\": question})\n",
    "    return {\"documents\": documents, \"question\": better_question}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f7b0802-9d4e-4748-9572-1d2db85a0c3d",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-11T07:46:10.192032Z",
     "iopub.status.busy": "2024-07-11T07:46:10.191660Z",
     "iopub.status.idle": "2024-07-11T07:46:10.195673Z",
     "shell.execute_reply": "2024-07-11T07:46:10.195152Z",
     "shell.execute_reply.started": "2024-07-11T07:46:10.192012Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def decide_to_generate(state):\n",
    "    \"\"\"\n",
    "    Determines whether to generate an answer, or re-generate a question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Binary decision for next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---ASSESS GRADED DOCUMENTS---\")\n",
    "    state[\"question\"]\n",
    "    filtered_documents = state[\"documents\"]\n",
    "\n",
    "    if not filtered_documents:\n",
    "        # All documents have been filtered check_relevance\n",
    "        # We will re-generate a new query\n",
    "        print(\n",
    "            \"---DECISION: 所有文档不相干，重写问题---\"\n",
    "        )\n",
    "        return \"transform_query\"\n",
    "    else:\n",
    "        # We have relevant documents, so generate answer\n",
    "        print(\"---DECISION:文档相关，生成新的答案---\")\n",
    "        return \"generate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "092d0fad-2f29-49d5-95e5-724c4b7116ca",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-11T07:46:11.885354Z",
     "iopub.status.busy": "2024-07-11T07:46:11.885001Z",
     "iopub.status.idle": "2024-07-11T07:46:11.890373Z",
     "shell.execute_reply": "2024-07-11T07:46:11.889777Z",
     "shell.execute_reply.started": "2024-07-11T07:46:11.885335Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "def grade_generation_v_documents_and_question(state):\n",
    "    \"\"\"\n",
    "    Determines whether the generation is grounded in the document and answers question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Decision for next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---检查是否存在幻觉---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    generation = state[\"generation\"]\n",
    "    dok_tmp = '\\n\\n'.join([dk.page_content for dk in documents])\n",
    "\n",
    "    score = hallucination_grader.invoke(\n",
    "        {\"documents\": dok_tmp, \"generation\": generation}\n",
    "    )\n",
    "    grade = score.binary_score\n",
    "\n",
    "    # Check hallucination\n",
    "    if grade == \"yes\":\n",
    "        print(\"---DECISION: 生成的回答是基于文档的---\")\n",
    "        # Check question-answering\n",
    "        print(\"---GRADE GENERATION vs QUESTION---\")\n",
    "        score = answer_grader.invoke({\"question\": question, \"generation\": generation})\n",
    "        grade = score.binary_score\n",
    "        if grade == \"yes\":\n",
    "            print(\"---DECISION: 生成回答解决得来问题---\")\n",
    "            return \"useful\"\n",
    "        else:\n",
    "            print(\"---DECISION: 生成回答不解决问题---\")\n",
    "            return \"not useful\"\n",
    "    else:\n",
    "        pprint(\"---DECISION: 生成回答不以文档为基础，重写问题---\")\n",
    "        return \"not supported\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "680b085e-6bb0-4ce6-9b12-6af7340f1f46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-11T07:46:46.652631Z",
     "iopub.status.busy": "2024-07-11T07:46:46.652267Z",
     "iopub.status.idle": "2024-07-11T07:46:46.659069Z",
     "shell.execute_reply": "2024-07-11T07:46:46.658481Z",
     "shell.execute_reply.started": "2024-07-11T07:46:46.652611Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph, START\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Define the nodes\n",
    "workflow.add_node(\"retrieve\", retrieve)  # retrieve\n",
    "workflow.add_node(\"grade_documents\", grade_documents)  # grade documents\n",
    "workflow.add_node(\"generate\", generate)  # generatae\n",
    "workflow.add_node(\"transform_query\", transform_query)  # transform_query\n",
    "\n",
    "# Build graph\n",
    "workflow.add_edge(START, \"retrieve\")\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    decide_to_generate,\n",
    "    {\n",
    "        \"transform_query\": \"transform_query\",\n",
    "        \"generate\": \"generate\",\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"transform_query\", \"retrieve\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"generate\",\n",
    "    grade_generation_v_documents_and_question,\n",
    "    {\n",
    "        \"not supported\": \"generate\",\n",
    "        \"useful\": END,\n",
    "        \"not useful\": \"transform_query\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# Compile\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4aa2ddd6-08a4-4924-bf6b-d443dcc165b9",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-11T07:46:50.637477Z",
     "iopub.status.busy": "2024-07-11T07:46:50.637040Z",
     "iopub.status.idle": "2024-07-11T07:47:29.414685Z",
     "shell.execute_reply": "2024-07-11T07:47:29.413704Z",
     "shell.execute_reply.started": "2024-07-11T07:46:50.637447Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---检索文档中---\n",
      "\"Node 'retrieve':\"\n",
      "'\\n---\\n'\n",
      "---检查该问题是否与检索文档相关---\n",
      "---GRADE: 该文档与结果相关---\n",
      "---GRADE: 该文档与结果不相关---\n",
      "---GRADE: 该文档与结果相关---\n",
      "---GRADE: 该文档与结果相关---\n",
      "---GRADE: 该文档与结果不相关---\n",
      "---GRADE: 该文档与结果不相关---\n",
      "---GRADE: 该文档与结果相关---\n",
      "---GRADE: 该文档与结果不相关---\n",
      "---GRADE: 该文档与结果不相关---\n",
      "---GRADE: 该文档与结果不相关---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION:文档相关，生成新的答案---\n",
      "\"Node 'grade_documents':\"\n",
      "'\\n---\\n'\n",
      "---正在根据检索结果 生成回答---\n",
      "---检查是否存在幻觉---\n",
      "---DECISION: 生成的回答是基于文档的---\n",
      "---GRADE GENERATION vs QUESTION---\n",
      "---DECISION: 生成回答解决得来问题---\n",
      "\"Node 'generate':\"\n",
      "'\\n---\\n'\n",
      "('High-yielding soybeans, from a phenotypic perspective, exhibit several '\n",
      " 'characteristics that contribute to their superior yield potential. Based on '\n",
      " 'the provided context, the following points can be noted:\\n'\n",
      " '\\n'\n",
      " '1. **Growth Rate**: High-yielding soybeans tend to have an optimal growth '\n",
      " 'rate during both the vegetative and reproductive phases. The critical period '\n",
      " 'for seed number determination is significantly influenced by crop growth '\n",
      " 'rate, duration, and dry matter accumulation (Monzon et al., 2021). Thus, a '\n",
      " 'robust growth rate during these phases is likely a key characteristic of '\n",
      " 'high-yielding soybeans.\\n'\n",
      " '\\n'\n",
      " '2. **Stress Tolerance**: Given that stress, particularly during the '\n",
      " 'reproductive phase, is a major limitation to high yield, high-yielding '\n",
      " 'soybeans would be expected to exhibit better tolerance to various stresses '\n",
      " 'such as drought, heat, or disease.\\n'\n",
      " '\\n'\n",
      " '3. **Plant Architecture**: Newer high-yielding cultivars tend to have a '\n",
      " 'shorter plant height, which is associated with reduced lodging (Specht and '\n",
      " 'Williams, 1984; Rincker et al., 2014). Lodging can negatively affect yield '\n",
      " \"by reducing the plant's ability to photosynthesize and transfer resources.\\n\"\n",
      " '\\n'\n",
      " '4. **Reproductive Characteristics**: The relationship between seed number '\n",
      " 'per unit land area, weight per seed, and yield is critical. High-yielding '\n",
      " 'soybeans would likely have an optimal balance between these factors, '\n",
      " 'resulting in maximum seed output per unit area.\\n'\n",
      " '\\n'\n",
      " '5. **Timing and Duration of Growth Phases**: The timing and duration of the '\n",
      " 'vegetative and reproductive phases are crucial in determining final yield. '\n",
      " 'High-yielding soybeans would have phenotypes that allow for an appropriate '\n",
      " 'and timely transition between these phases, ensuring that the reproductive '\n",
      " 'phase occurs under favorable conditions.\\n'\n",
      " '\\n'\n",
      " '6. **Dry Matter Accumulation**: Efficient conversion of solar energy into '\n",
      " 'dry matter is a hallmark of high-yielding crops. Soybeans with a high yield '\n",
      " 'potential would accumulate dry matter effectively during their growth '\n",
      " 'cycle.\\n'\n",
      " '\\n'\n",
      " 'In summary, the phenotypic characteristics of high-yielding soybeans would '\n",
      " 'include an optimal growth rate, stress tolerance, appropriate plant height '\n",
      " 'to prevent lodging, effective reproductive characteristics, and efficient '\n",
      " 'dry matter accumulation. The synchronization of these traits with the growth '\n",
      " 'phases is also critical for maximizing yield.')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# Run\n",
    "inputs = {\"question\": \"What are the characteristics of high-yielding soybeans phenotypically, such as growth rate? Answer as much as you can.\"}\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        # Node\n",
    "        pprint(f\"Node '{key}':\")\n",
    "        # Optional: print full state at each node\n",
    "        # pprint.pprint(value[\"keys\"], indent=2, width=80, depth=None)\n",
    "    pprint(\"\\n---\\n\")\n",
    "\n",
    "# Final generation\n",
    "pprint(value[\"generation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b83bb2c-5af1-451f-9d8c-ae9842aa188a",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-11T08:04:06.687273Z",
     "iopub.status.busy": "2024-07-11T08:04:06.686846Z",
     "iopub.status.idle": "2024-07-11T08:04:06.690872Z",
     "shell.execute_reply": "2024-07-11T08:04:06.690269Z",
     "shell.execute_reply.started": "2024-07-11T08:04:06.687244Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-yielding soybeans, from a phenotypic perspective, exhibit several characteristics that contribute to their superior yield potential. Based on the provided context, the following points can be noted:\n",
      "\n",
      "1. **Growth Rate**: High-yielding soybeans tend to have an optimal growth rate during both the vegetative and reproductive phases. The critical period for seed number determination is significantly influenced by crop growth rate, duration, and dry matter accumulation (Monzon et al., 2021). Thus, a robust growth rate during these phases is likely a key characteristic of high-yielding soybeans.\n",
      "\n",
      "2. **Stress Tolerance**: Given that stress, particularly during the reproductive phase, is a major limitation to high yield, high-yielding soybeans would be expected to exhibit better tolerance to various stresses such as drought, heat, or disease.\n",
      "\n",
      "3. **Plant Architecture**: Newer high-yielding cultivars tend to have a shorter plant height, which is associated with reduced lodging (Specht and Williams, 1984; Rincker et al., 2014). Lodging can negatively affect yield by reducing the plant's ability to photosynthesize and transfer resources.\n",
      "\n",
      "4. **Reproductive Characteristics**: The relationship between seed number per unit land area, weight per seed, and yield is critical. High-yielding soybeans would likely have an optimal balance between these factors, resulting in maximum seed output per unit area.\n",
      "\n",
      "5. **Timing and Duration of Growth Phases**: The timing and duration of the vegetative and reproductive phases are crucial in determining final yield. High-yielding soybeans would have phenotypes that allow for an appropriate and timely transition between these phases, ensuring that the reproductive phase occurs under favorable conditions.\n",
      "\n",
      "6. **Dry Matter Accumulation**: Efficient conversion of solar energy into dry matter is a hallmark of high-yielding crops. Soybeans with a high yield potential would accumulate dry matter effectively during their growth cycle.\n",
      "\n",
      "In summary, the phenotypic characteristics of high-yielding soybeans would include an optimal growth rate, stress tolerance, appropriate plant height to prevent lodging, effective reproductive characteristics, and efficient dry matter accumulation. The synchronization of these traits with the growth phases is also critical for maximizing yield.\n"
     ]
    }
   ],
   "source": [
    "print(value[\"generation\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
