{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc81a148-9269-4eb3-b06e-7b959f1eaaea",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-12T02:06:44.072533Z",
     "iopub.status.busy": "2024-07-12T02:06:44.072173Z",
     "iopub.status.idle": "2024-07-12T02:06:45.040131Z",
     "shell.execute_reply": "2024-07-12T02:06:45.039625Z",
     "shell.execute_reply.started": "2024-07-12T02:06:44.072512Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "documents = []\n",
    "dc_name = [\"soybean_konw.pdf\", \"soybean2.pdf\"]\n",
    "for tmp_name in dc_name:\n",
    "    # print(len(PyPDFLoader(tmp_name).load()))\n",
    "    documents += PyPDFLoader(tmp_name).load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=200)\n",
    "texts = text_splitter.split_documents(documents[:])\n",
    "for idx, text in enumerate(texts):\n",
    "    text.metadata[\"id\"] = idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c82bbb1-0aa7-4b70-ae05-429974bdb4a0",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-04T08:39:19.193147Z",
     "iopub.status.busy": "2024-07-04T08:39:19.192324Z",
     "iopub.status.idle": "2024-07-04T08:39:19.433222Z",
     "shell.execute_reply": "2024-07-04T08:39:19.432730Z",
     "shell.execute_reply.started": "2024-07-04T08:39:19.193109Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.6,\n",
    "    model=\"glm-4-0520\",\n",
    "    openai_api_key=\"661a7aa0aeb8ca129eb4647461123230.bl9w581QKpnMfBvs\",\n",
    "    openai_api_base=\"https://open.bigmodel.cn/api/paas/v4/\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6bad46e-1eba-4db4-b811-0d3d1cb22712",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T08:39:23.337725Z",
     "iopub.status.busy": "2024-07-04T08:39:23.337360Z",
     "iopub.status.idle": "2024-07-04T08:39:23.341948Z",
     "shell.execute_reply": "2024-07-04T08:39:23.341484Z",
     "shell.execute_reply.started": "2024-07-04T08:39:23.337702Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from typing import Literal, Optional, Tuple\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "class Soybean_Q_GT(BaseModel):\n",
    "\n",
    "    question: str = Field(\n",
    "        ..., description=\"Given contextual information, not prior knowledge. Generate questions based only on the following queries.\"\n",
    "    )\n",
    "    ground_truth: str = Field(\n",
    "        ..., description=\"Given contextual information, not prior knowledge. Give the corresponding answers only according to the questions generated above.\"\n",
    "    )\n",
    "\n",
    "# Set up a parser\n",
    "parser = PydanticOutputParser(pydantic_object=Soybean_Q_GT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f03d3fb9-238b-4e35-a4ed-cd05afb03e8a",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2024-07-04T08:39:26.921598Z",
     "iopub.status.busy": "2024-07-04T08:39:26.921181Z",
     "iopub.status.idle": "2024-07-04T08:39:26.928103Z",
     "shell.execute_reply": "2024-07-04T08:39:26.927558Z",
     "shell.execute_reply.started": "2024-07-04T08:39:26.921570Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "# Prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Answer the user query. Wrap the output in `json` tags\\n{format_instructions}\",\n",
    "        ),\n",
    "        (\n",
    "            \"human\", \n",
    "            \"\"\"\n",
    "            Context information is below.\n",
    "            ---------------------\n",
    "            {context}\n",
    "            ---------------------\n",
    "            Given contextual information, not prior knowledge. Ask questions and find out the truth in the context below. You're a college professor. Your task is to write questions for the upcoming exam and give the corresponding standard answers. The questions should be varied throughout the exam.\n",
    "            Questions must be written in Chinese. The questions should be abstract, no more than 30 Chinese characters. The standard answers should be as varied and varied as possible, with slightly more words, under 100 words.\n",
    "            Punctuation such as \"this\", \"that\", \"according\" and \"according\" should not be used. Acronyms can be used for titles and technical terms. \n",
    "            \"\"\"\n",
    "        ),\n",
    "    ]\n",
    ").partial(format_instructions=parser.get_format_instructions())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "921bd98d-42c7-4988-b38e-7ea358db71b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T08:39:38.551644Z",
     "iopub.status.busy": "2024-07-04T08:39:38.551265Z",
     "iopub.status.idle": "2024-07-04T08:39:38.555071Z",
     "shell.execute_reply": "2024-07-04T08:39:38.554541Z",
     "shell.execute_reply.started": "2024-07-04T08:39:38.551622Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "    {\"context\": RunnablePassthrough()} \n",
    "    | prompt \n",
    "    | llm\n",
    "    | parser \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4071f8ec-d86a-407b-80b4-279d2c501bcc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"北豆40，为产于黑龙江省的大豆种子。是由黑龙江省农垦总局红兴隆科学研究所与黑龙江省农垦科研育种中心共同研发的产品。品种特性该品种平均生育期120天，长叶、紫花、亚有限结荚习性。株高85.8厘米，单株有效荚数34.4个，百粒重19.0克。籽粒圆形，种皮黄色，黄脐。接种鉴定，中抗大豆灰斑病，中抗SMVⅠ号株系，中感SMVⅢ号株系。粗蛋白质含量40.78%，粗脂肪含量21.99%。产量表现2006年参加北方春大豆中早熟组品种区域试验，亩产210.6千克，比对照绥农14增产4.0%，极显著；2007年续试，亩产181.2千克，比对照增产6.5%，极显著；两年区域试验亩产195.9千克，比对照增产5.2%。2007年生产试验，亩产166.8千克，比对照增产5.2%。栽培技术要点地温稳定通过7～8℃开始播种，适宜种植密度为每亩1.6万～1.7万株；以深秋施肥为好，每亩施纯量化肥8～10千克，氮、磷、钾比例1∶1.15～1.5∶0.8。该品种符合国家大豆品种审定标准，通过审定。适宜在黑龙江省第二积温带和第三积温带上限，吉林省东部地区春播种植。\"\n",
    "\n",
    "print(prompt.invoke(query).to_string())\n",
    "z = rag_chain.invoke({\"context\": query})\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c71c3f06-555a-4445-bd6f-70cf2800630c",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-04T08:39:41.556268Z",
     "iopub.status.busy": "2024-07-04T08:39:41.555956Z",
     "iopub.status.idle": "2024-07-04T08:39:41.560100Z",
     "shell.execute_reply": "2024-07-04T08:39:41.559643Z",
     "shell.execute_reply.started": "2024-07-04T08:39:41.556248Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "content = [texts[i].page_content for i in range(len(texts))]\n",
    "idk = [texts[i].metadata['id'] for i in range(len(texts))]\n",
    "source = [texts[i].metadata['source'] for i in range(len(texts))]\n",
    "page = [texts[i].metadata['page'] for i in range(len(texts))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e57ee08a-3b8b-4fe8-b535-b0ff695c60e4",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-04T08:39:43.615796Z",
     "iopub.status.busy": "2024-07-04T08:39:43.615424Z",
     "iopub.status.idle": "2024-07-04T08:40:53.620404Z",
     "shell.execute_reply": "2024-07-04T08:40:53.619920Z",
     "shell.execute_reply.started": "2024-07-04T08:39:43.615775Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "609\n"
     ]
    }
   ],
   "source": [
    "question_gt = rag_chain.batch(content[:])\n",
    "print(len(question_gt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df316738-de08-4bc4-b268-bbe360eaf675",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T08:41:09.993427Z",
     "iopub.status.busy": "2024-07-04T08:41:09.992908Z",
     "iopub.status.idle": "2024-07-04T08:41:09.997276Z",
     "shell.execute_reply": "2024-07-04T08:41:09.996689Z",
     "shell.execute_reply.started": "2024-07-04T08:41:09.993405Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "question_list, ground_th_list = [], []\n",
    "for j in question_gt:\n",
    "    question_list.append(j.question)\n",
    "    ground_th_list.append(j.ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9312be52-3204-4add-85d4-062fe819334f",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 示例字典\n",
    "data_dict = {\n",
    "    'id': idk,\n",
    "    'source': source,\n",
    "    'page': page,\n",
    "    'question': question_list,\n",
    "    'ground_truth': ground_th_list,\n",
    "    'context': content[:]\n",
    "}\n",
    "\n",
    "# 将字典转换为Pandas DataFrame\n",
    "df = pd.DataFrame(data_dict)\n",
    "\n",
    "# 打印DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9885d7ab-9bae-4a96-9bc6-f5bb188aacdc",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-04T08:41:16.898976Z",
     "iopub.status.busy": "2024-07-04T08:41:16.898613Z",
     "iopub.status.idle": "2024-07-04T08:41:16.992559Z",
     "shell.execute_reply": "2024-07-04T08:41:16.991246Z",
     "shell.execute_reply.started": "2024-07-04T08:41:16.898952Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_excel('soybean_q_gt_609_.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
